{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"opp4Cld9gck7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655471828586,"user_tz":-60,"elapsed":10658,"user":{"displayName":"Sarah-Louise Hayes","userId":"13751648430878105914"}},"outputId":"429f6bb5-93e2-4c72-9112-5cb13ff28add"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device cuda:0\n"]},{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7fcf1ba9b190>"]},"metadata":{},"execution_count":1}],"source":["!pip install -r /content/drive/MyDrive/Dissertation/requirements.txt -qqq\n","!pip install ipdb -qqq\n","\n","\n","from datetime import datetime\n","import json\n","import torch\n","import torchvision\n","import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","import os\n","import numpy as np\n","import torchvision.models as models\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch import argmax\n","from tqdm import tqdm\n","from PIL import Image\n","from matplotlib import pyplot as plt\n","import seaborn as sn\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score, f1_score, classification_report, balanced_accuracy_score\n",")\n","from torchsampler import ImbalancedDatasetSampler\n","import wandb\n","import numpy as np\n","from os import listdir\n","from os.path import join, isdir\n","from glob import glob\n","import cv2\n","import timeit\n","import timm\n","from sklearn.metrics import confusion_matrix\n","from torchvision.datasets import ImageFolder\n","from collections import Counter\n","from sklearn.utils import class_weight\n","from torchvision.transforms import AutoAugment\n","from operator import itemgetter\n","import random\n","\n","from torchvision.transforms.autoaugment import AutoAugmentPolicy\n","\n","#changing the device to GPU rather than CPU if it is available,\n","# this will decrease model training time.\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device {}\".format(device))\n","\n","torch.manual_seed(17)"]},{"cell_type":"markdown","metadata":{"id":"ZeVHonwolOyZ"},"source":["## Network generation\n","\n","Five networks were created using several architectures loaded from the Pytroch library.  Within each model-specific function, the feature extraction layers have been frozen and the final classification layer unfrozen, to allow this final layer to train on our Lesion dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bxMWZ9CIlK7B"},"outputs":[],"source":["def create_network_densenet():\n","        net = models.densenet161(pretrained=True)\n","        net.classifier = nn.Linear(in_features=2208, out_features=8, bias=True)\n","\n","        for param in net.parameters():\n","                param.requires_grad = False\n","        for param in net.classifier.parameters():\n","                param.requires_grad = True\n","\n","        return net\n"]},{"cell_type":"code","source":["class ImageFolderWithPaths(ImageFolder):\n","\n","    def __getitem__(self, index: int):\n","        path, target = self.samples[index]\n","        sample = self.loader(path)\n","        if self.transform is not None:\n","            sample = self.transform(sample)\n","        if self.target_transform is not None:\n","            target = self.target_transform(target)\n","\n","        return sample, target, path"],"metadata":{"id":"FYQuy_tlq9BV"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xDTi6y0Uk7N9"},"outputs":[],"source":["def run(config):  \n","    torch.manual_seed(17)\n","    BASE_PATH = '/content/drive/MyDrive/Dissertation/skin_lesion_data/skin_lesion_part_1_models/'\n","    now = str(datetime.now()).replace(\":\", \"-\").replace(\" \", \"_\")\n","    RESULTS_PATH = os.path.join(BASE_PATH, now)\n","    os.makedirs(RESULTS_PATH, exist_ok=False)\n","\n","    with open(os.path.join(RESULTS_PATH, \"config.json\"), \"w\") as f:\n","        json.dump(config, f, indent=4)\n","\n","    if config.get(\"use_wandb\"):\n","        # this integrates the third-party platform, Weights and Biases,\n","        # with this notebook.\n","        run = wandb.init(\n","            project=\"part_1_skin_lesion\",\n","            entity=\"sarahlouise\",\n","            config=config,\n","        )\n","\n","\n","    # ## Train, validation and test set\n","    #\n","    # The train, validation and test sets were loaded and transformed using the Pytorch functions and amended classes previously discussed.\n","\n","    batch_size = config[\"batch_size\"]\n","    Imagenet_NV = ((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","\n","    print(\"Configuring datasets\")\n","    trainset = ImageFolder(\n","        os.path.join(config.get(\"data_path\"), 'train'),\n","        transform=transforms.Compose([\n","                                   ## v2 own inspired   \n","                            #           transforms.RandomVerticalFlip(0.5),\n","                            # transforms.RandomHorizontalFlip(0.5),\n","                            # transforms.RandomApply(nn.ModuleList([transforms.ColorJitter(),\n","                            #                                 transforms.GaussianBlur(3)]), p=0.1),\n","                            ## v1 Gessert Inspired \n","                            # ImageResize(224,224),\n","                            # transforms.RandomVerticalFlip(0.5),\n","                            # transforms.RandomHorizontalFlip(0.5),\n","                            # transforms.RandomApply(\n","                            #     nn.ModuleList([\n","                            #                    transforms.ColorJitter(brightness=32. / 255.,saturation=0.5),\n","                            #                    transforms.RandomRotation(degrees=(0, 360)),\n","                                               #transforms.CenterCrop(100)\n","                                            #    ]), p=0.1),\n","                            # transforms.AutoAugment(AutoAugmentPolicy.IMAGENET),\n","                            ## v3 own inspired\n","                            transforms.RandomVerticalFlip(0.5),\n","                            transforms.RandomHorizontalFlip(0.5),\n","                            transforms.RandomApply(nn.ModuleList([transforms.RandomRotation(degrees=(0, 360))]), p=0.2),\n","                            ImageResize(224,224),\n","                            transforms.PILToTensor(),\n","                            transforms.ConvertImageDtype(torch.float),\n","                            transforms.Normalize(*Imagenet_NV),\n","\n","                        ])\n","        )\n","    \n","    imbalanced_sampler_choice = [\n","        config.get(\"use_custom_imbalanced_sampler\"),\n","        config.get(\"use_imbalanced_sampler\"),\n","        config.get(\"use_RandomImbalancedDatasetSampler\"),\n","        config.get(\"WorstCustomImbalancedDatasetSampler\"),\n","        config.get(\"ClassBasedCustomImbalancedDatasetSampler\"),\n","        config.get(\"ClassBasedRandomImbalancedDatasetSampler\"),\n","        config.get(\"ClassBasedWorstImbalancedDatasetSampler\"),\n","    ]\n","    if imbalanced_sampler_choice.count(True) > 1:\n","        raise ValueError(\"Pick one sampler, cant use all\")\n","\n","\n","    # if config.get(\"use_custom_imbalanced_sampler\") and config.get(\"use_imbalanced_sampler\") and config.get(\"use_RandomImbalancedDatasetSampler\") and config.get(\"WorstCustomImbalancedDatasetSampler\"):\n","    #     raise ValueError(\"Pick one sampler, cant use all\")\n","\n","    elif config.get(\"use_custom_imbalanced_sampler\"):\n","        sampler = CustomImbalancedDatasetSampler(\n","            dataset=trainset,\n","            callback_get_label=lambda x: x.targets,\n","            top_percent_keep=config.get(\"percent_keep\"), \n","            path_brisque_score=\"/content/drive/MyDrive/Dissertation/skin_lesion_data/v2_prepro_brisque_metrics.json\",\n","        )\n","        shuffle = False\n","    elif config.get(\"use_imbalanced_sampler\"):\n","        sampler = ImbalancedDatasetSampler(\n","            trainset,\n","            callback_get_label=lambda x: x.targets,\n","        )\n","        shuffle = False\n","    elif config.get(\"use_RandomImbalancedDatasetSampler\"):\n","        sampler = RandomImbalancedDatasetSampler(\n","            trainset,\n","            callback_get_label=lambda x: x.targets,\n","            random_percent_keep=config.get(\"percent_keep\"),\n","        )\n","        shuffle = False\n","    elif config.get(\"WorstCustomImbalancedDatasetSampler\"):\n","        sampler = RandomImbalancedDatasetSampler(\n","            trainset,\n","            callback_get_label=lambda x: x.targets,\n","            random_percent_keep=config.get(\"percent_keep\"),\n","        )\n","        shuffle = False\n","    elif config.get(\"ClassBasedCustomImbalancedDatasetSampler\"):\n","        sampler = ClassBasedCustomImbalancedDatasetSampler(\n","            dataset=trainset,\n","            callback_get_label=lambda x: x.targets,\n","            top_percent_keep=config.get(\"percent_keep\"), \n","            path_brisque_score=\"/content/drive/MyDrive/Dissertation/skin_lesion_data/v2_prepro_brisque_metrics.json\",\n","        )\n","        shuffle = False\n","    elif config.get(\"ClassBasedRandomImbalancedDatasetSampler\"):\n","        sampler = ClassBasedRandomImbalancedDatasetSampler(\n","            trainset,\n","            callback_get_label=lambda x: x.targets,\n","            random_percent_keep=config.get(\"percent_keep\"),\n","            # Only using to get class breakdown\n","            path_brisque_score=\"/content/drive/MyDrive/Dissertation/skin_lesion_data/v2_prepro_brisque_metrics.json\",\n","        )\n","        shuffle=False\n","    elif config.get(\"ClassBasedWorstImbalancedDatasetSampler\"):\n","        sampler = ClassBasedWorstImbalancedDatasetSampler(\n","            trainset,\n","            callback_get_label=lambda x: x.targets,\n","            percent_keep=config.get(\"percent_keep\"),\n","            path_brisque_score=\"/content/drive/MyDrive/Dissertation/skin_lesion_data/v2_prepro_brisque_metrics.json\",\n","        )\n","        shuffle = False\n","    else:\n","        sampler = None\n","        shuffle = True\n","\n","\n","    trainloader = torch.utils.data.DataLoader(\n","        trainset,\n","        batch_size=batch_size,\n","        num_workers=2,\n","        shuffle=shuffle,\n","        sampler=sampler,\n","    )\n","\n","    valset = ImageFolder(\n","        os.path.join(config.get(\"data_path\"), 'val'),\n","        transform=transforms.Compose([\n","                            # PILtoCV2(),\n","                            # HairRemoval(),\n","                            # CropBlackCircle(),\n","                            # ShadesOfGrey(),\n","                            # CV2toPIL(),\n","                            ImageResize(224,224),\n","                            transforms.PILToTensor(),\n","                            transforms.ConvertImageDtype(torch.float),\n","                            transforms.Normalize(*Imagenet_NV),\n","                        ]))\n","\n","    valloader = torch.utils.data.DataLoader(\n","        valset,\n","        batch_size=batch_size,\n","        shuffle=False,\n","        num_workers=2\n","    )\n","\n","    testset = ImageFolderWithPaths(\n","        os.path.join(config.get(\"data_path\"), 'test'),\n","        transform=transforms.Compose([\n","                                # PILtoCV2(),\n","                                # HairRemoval(),\n","                                # CropBlackCircle(),\n","                                # ShadesOfGrey(),\n","                                # CV2toPIL(),\n","                                ImageResize(224,224),\n","                                transforms.PILToTensor(),\n","                                transforms.ConvertImageDtype(torch.float),\n","                                transforms.Normalize(*Imagenet_NV),\n","                            ]))\n","\n","    testloader = torch.utils.data.DataLoader(\n","        testset,\n","        batch_size=batch_size,\n","        shuffle=False,\n","        num_workers=2\n","    )\n","    \n","    classes = sorted(os.listdir(os.path.join(config.get(\"data_path\"), 'train')))\n","\n","    if config.get(\"use_wandb\"):\n","        wandb.sklearn.plot_class_proportions(\n","            trainset.targets,\n","            testset.targets,\n","            classes\n","        )\n","\n","\n","    #making logical arguments from the configuration dictionary definied earlier\n","    model_name = config[\"model\"]\n","\n","    if model_name == \"densenet\":\n","        net = create_network_densenet()\n","    elif model_name == \"efficientnet\":\n","        net = create_network_efficientnet()\n","    elif model_name == \"mobilenet\":\n","        net = create_network_mobilenet()\n","    elif model_name == \"resnet\":\n","        net = create_network_resnet()\n","    else:\n","        raise ValueError(\"Model name not supported '{}'\".format(model_name))\n","\n","    print(f\"Moving network to {device}\")\n","    net = net.to(device)\n","\n","    # ## Training configurations\n","    \n","    # defining the training configurations\n","    no_of_epochs = config[\"epochs\"]\n","    \n","    # calculating class weights\n","\n","    labels = np.array(trainset.targets)\n","    \n","    class_weights = class_weight.compute_class_weight(\n","        class_weight='balanced',\n","        classes=np.unique(labels),\n","        y=labels\n","    )\n","    class_weights = torch.tensor(\n","        class_weights,\n","        dtype=torch.float\n","    )\n","\n","    if config.get(\"use_weighted_loss\"):\n","        criterion = nn.CrossEntropyLoss(weight=class_weights).to(device)\n","    else:\n","        criterion = nn.CrossEntropyLoss().to(device)\n","\n","    optimizer = optim.Adam(\n","        net.parameters(),\n","        lr=config[\"lr\"],\n","        amsgrad=config[\"use_amsgrad\"]\n","    )\n","\n","    if config[\"use_warm_restarts\"]:\n","        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n","            optimizer,\n","            T_0=10,\n","            T_mult=1,\n","        )\n","    else:\n","        scheduler = optim.lr_scheduler.CosineAnnealingLR(\n","            optimizer,\n","            round((len(trainset)/batch_size)*no_of_epochs)\n","        )\n","\n","\n","    # ##  Model training\n","    #\n","    # This section included the training for the model. The network was set to train, a mini-batch was passed through the model and then the loss was then backpropagated. Each trained model was also automatically saved.\n","\n","    if config.get(\"use_wandb\"):\n","        wandb.watch(net)\n","\n","    if not config.get(\"use_pretrained\"):\n","        print(\"Starting training\")\n","        for epoch in range(no_of_epochs):  # loop over the dataset multiple times\n","            print(\"Epoch {} of {}\".format(epoch+1, no_of_epochs))\n","            epoch_running_loss = []\n","            epoch_val_metric = []\n","            for i, data in tqdm(enumerate(trainloader, 1), total=len(trainloader)):\n","                current_step = (len(trainloader) * epoch) + i\n","                \n","                # get the inputs; data is a list of [inputs, labels]\n","                net.train()\n","                \n","                inputs, labels = data\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","                \n","                # forward + backward\n","                outputs = net(inputs)\n","\n","                \n","                # outputs = torch.max(outputs, 1)\n","                loss = criterion(outputs, labels)\n","                \n","                loss.backward()\n","                optimizer.step()\n","                scheduler.step()\n","\n","                # saving loss statistics\n","                loss_val = loss.item()\n","                if config.get(\"use_wandb\"):\n","                    wandb.log(\n","                        {\n","                            \"train/bce_logits_loss\": loss_val,\n","                            \"train/lr\": scheduler.get_last_lr()[0],\n","                            \"train/custom_step\": (len(trainloader) * epoch) + i,\n","                        }\n","                    )\n","\n","                # adding in valiation data testing\n","                if i % round(40*config.get(\"percent_keep\", 1)) == 0:\n","                    model_name = \"{name}-epoch-{epoch}-step-{step}.pth\".format(\n","                        name=config[\"name\"],\n","                        epoch=epoch,\n","                        step=i,\n","                    )\n","                    model_path = os.path.join(RESULTS_PATH, model_name)\n","                    # Commenting out to save space\n","                    # torch.save(net.state_dict(), model_path)\n","\n","                    predicted = []\n","                    actual = []\n","\n","                    print(\"Running validation\")\n","                    net.eval()\n","                    with torch.no_grad():\n","                        for i, data in enumerate(tqdm(valloader, total=len(valloader))):\n","                            inputs, labels = data\n","                            inputs = inputs.to(device)\n","                            labels = labels.to(device)\n","\n","                            outputs = net(inputs)\n","                            loss = criterion(outputs, labels)\n","                            if config.get(\"use_wandb\"):\n","                                wandb.log({\n","                                    \"val/loss\": loss,\n","                                    \"val/custom_step\": current_step,\n","                                })\n","\n","                            # collect the correct predictions for each class\n","                            actual.extend(labels.detach().cpu().numpy())\n","                            predicted.extend(torch.argmax(outputs, 1).detach().cpu().numpy())\n","\n","                        mb_acc = accuracy_score(actual, predicted)\n","                        precision = precision_score(actual, predicted, average=\"macro\", zero_division = 1)\n","                        recall = recall_score(actual, predicted, average=\"macro\", zero_division = 1)\n","                        f1 = f1_score(actual, predicted, average=\"macro\", zero_division = 1)\n","                        bal_acc = balanced_accuracy_score(actual, predicted)\n","                        metric_report = classification_report(\n","                            np.array(actual),\n","                            np.array(predicted),\n","                            output_dict=True,\n","                            zero_division=1,\n","                        )\n","                        metric_report = {\n","                            f\"val_classes/{k}\": v\n","                            for k, v in metric_report.items()\n","                        }\n","                        metric_report.update({\n","                            \"val_classes/custom_step\": current_step,\n","                        })\n","\n","                        if config.get(\"use_wandb\"):\n","                            wandb.log({\n","                                \"val/accuracy\": mb_acc,\n","                                \"val/precision\": precision,\n","                                \"val/recall\": recall,\n","                                \"val/f1\": f1,\n","                                \"val/balanced_acc\": bal_acc,\n","                                \"val/custom_step\": current_step\n","                            })\n","                            wandb.log(metric_report)\n","\n","\n","\n","        print('Finished Training')\n","        # saving each trained model\n","        model_name = '{}-final.pth'.format(\n","            config[\"name\"]\n","        )\n","        model_path = os.path.join(RESULTS_PATH, model_name)\n","        torch.save(net.state_dict(), model_path)\n","\n","        print(\"Final model saved\")\n","\n","    # ##  Model testing\n","    #\n","    # The model was set to evaluate mode for testing. The predicted and actual results were saved, and used for generating a confusion matrix and metrics.\n","    #\n","    # A confusion matrix was generated, showing the number of true positives and negatives, and false positives and negatives. Additionally, the metrics were calculated, including the accuracy score, precision and recall. The corresponding graphs were created using Weights and Biases.\n","\n","\n","    if config.get(\"use_pretrained\"):\n","        net.load_state_dict(\n","            torch.load(\n","                config.get(\"use_pretrained\")\n","            )\n","        )\n","\n","    predicted = []\n","    actual = []\n","    image_paths = []\n","    \n","    print(\"Testing model\")\n","    # again no gradients needed\n","    net.eval()\n","    with torch.no_grad():\n","        for i, data in enumerate(tqdm(testloader, total=len(testloader))):\n","            inputs, labels, paths = data\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            outputs = net(inputs)\n","            actual.extend(labels.detach().cpu().numpy())\n","            predicted.extend(torch.argmax(outputs, 1).detach().cpu().numpy())\n","            image_paths.extend(paths)\n","\n","\n","    results = pd.DataFrame.from_dict(\n","        {\n","            \"predicted\": predicted,\n","            \"actual\": actual,\n","            \"image_path\": image_paths\n","        }\n","    )\n","    results.to_csv(os.path.join(RESULTS_PATH, \"each_image_predictions.csv\"))\n","\n","\n","    print(\"Calculating performance metrics\")\n","    model_accuracy = accuracy_score(actual, predicted)\n","    model_precision = precision = precision_score(actual, predicted,\n","                                                average=\"macro\", zero_division = 1)\n","    model_recall = recall_score(actual, predicted,\n","                                average=\"macro\", zero_division = 1)\n","    model_f1 = f1_score(actual, predicted, average=\"macro\", zero_division = 1)\n","    model_bal_acc = balanced_accuracy_score(actual, predicted)\n","    metric_report = classification_report(\n","        np.array(actual),\n","        np.array(predicted),\n","        output_dict=True,\n","        zero_division=1,\n","    )\n","    metric_report = {\n","        f\"test_classes/{k}\": v\n","        for k, v in metric_report.items()\n","    }\n","\n","    if config.get(\"use_wandb\"):\n","        wandb.log({\"test/accuracy\": model_accuracy})\n","        wandb.log({\"test/precision\": model_precision})\n","        wandb.log({\"test/recall\": model_recall})\n","        wandb.log({\"test/f1\": model_f1})\n","        wandb.log({\"test/bal_acc\": model_bal_acc})\n","        wandb.sklearn.plot_confusion_matrix(actual, predicted, classes, normalize=\"true\")\n","        wandb.log(metric_report)\n","    else:\n","        print(\"test/accuracy\", model_accuracy)\n","        print(\"test/precision\", model_precision)\n","        print(\"test/recall\", model_recall)\n","        print(\"test/f1\", model_f1)\n","        print(\"test/bal_acc\", model_bal_acc)\n","\n","    plot_save_path = os.path.join(RESULTS_PATH, '{}_confusion_matrix.png'.format(\n","        config[\"name\"]\n","    ))\n","    print(\"Plotting confusion matrix in {}\".format(plot_save_path))\n","\n","    print(\"Calculating\")\n","    conf_matrix = confusion_matrix(y_true=actual, y_pred=predicted, normalize=\"true\")\n","    print(\"Done\")\n","    fig =plt.figure(figsize=(20, 20))\n","    ax = fig.add_subplot(1,1,1)\n","    ax.matshow(conf_matrix, cmap=plt.cm.Reds)\n","\n","\n","    plt.xlabel('Predictions')\n","    plt.ylabel('Actuals')\n","    plt.title('Confusion Matrix')\n","    plt.savefig(plot_save_path)\n","    # plt.show()\n","\n","    if config.get(\"use_wandb\"):\n","        run.finish()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xjSeEY5BUdey","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e3a372cee97c48c2b26bad7bc3fa4a20","01313ed54f4a469f9c62c5708ec55fb5","b89f20c681a44f6a97ef55fba5a99f3e","c79e528f19db4c9c93a5a9b1b8f542d4","285688636bd04fefa3b919aed2b2aa8a","673502cf24044b4080322978fe488439","aac4a1d0c70d44b3a56f5be195ca7189","ffa9428d16ff41528f1786674d7282ca"]},"outputId":"cccc1694-2cdf-4943-ac2e-70525436c570","executionInfo":{"status":"ok","timestamp":1655477562674,"user_tz":-60,"elapsed":5733628,"user":{"displayName":"Sarah-Louise Hayes","userId":"13751648430878105914"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msarahlouise\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.12.18"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20220617_131710-25fhy4fr</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/sarahlouise/part_1_skin_lesion/runs/25fhy4fr\" target=\"_blank\">wobbly-sponge-177</a></strong> to <a href=\"https://wandb.ai/sarahlouise/part_1_skin_lesion\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Configuring datasets\n","Moving network to cuda:0\n","Starting training\n","Epoch 1 of 5\n"]},{"output_type":"stream","name":"stderr","text":[" 49%|████▉     | 39/80 [17:43<20:19, 29.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [02:44<24:36, 164.07s/it]\u001b[A\n"," 20%|██        | 2/10 [02:45<09:06, 68.34s/it] \u001b[A\n"," 30%|███       | 3/10 [04:47<10:49, 92.77s/it]\u001b[A\n"," 40%|████      | 4/10 [04:47<05:38, 56.36s/it]\u001b[A\n"," 50%|█████     | 5/10 [06:49<06:39, 79.84s/it]\u001b[A\n"," 60%|██████    | 6/10 [06:49<03:31, 52.88s/it]\u001b[A\n"," 70%|███████   | 7/10 [08:47<03:41, 73.95s/it]\u001b[A\n"," 80%|████████  | 8/10 [08:47<01:41, 50.58s/it]\u001b[A\n"," 90%|█████████ | 9/10 [10:50<01:13, 73.24s/it]\u001b[A\n","100%|██████████| 10/10 [10:51<00:00, 65.13s/it]\n"," 99%|█████████▉| 79/80 [40:36<00:20, 21.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:08<01:16,  8.47s/it]\u001b[A\n"," 20%|██        | 2/10 [00:09<00:30,  3.83s/it]\u001b[A\n"," 30%|███       | 3/10 [00:16<00:37,  5.35s/it]\u001b[A\n"," 40%|████      | 4/10 [00:16<00:20,  3.48s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:24<00:25,  5.12s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:25<00:14,  3.59s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:29<00:10,  3.59s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:29<00:05,  2.64s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:37<00:04,  4.14s/it]\u001b[A\n","100%|██████████| 10/10 [00:37<00:00,  3.77s/it]\n","100%|██████████| 80/80 [41:14<00:00, 30.93s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 of 5\n"]},{"output_type":"stream","name":"stderr","text":["\n"," 49%|████▉     | 39/80 [10:28<11:03, 16.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:10<01:32, 10.30s/it]\u001b[A\n"," 20%|██        | 2/10 [00:10<00:37,  4.63s/it]\u001b[A\n"," 30%|███       | 3/10 [00:20<00:46,  6.71s/it]\u001b[A\n"," 40%|████      | 4/10 [00:20<00:25,  4.30s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:30<00:31,  6.37s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:31<00:17,  4.43s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:36<00:13,  4.63s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:37<00:06,  3.36s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:46<00:05,  5.34s/it]\u001b[A\n","100%|██████████| 10/10 [00:47<00:00,  4.75s/it]\n"," 99%|█████████▉| 79/80 [19:00<00:14, 14.50s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:08<01:17,  8.63s/it]\u001b[A\n"," 20%|██        | 2/10 [00:09<00:31,  3.94s/it]\u001b[A\n"," 30%|███       | 3/10 [00:16<00:37,  5.33s/it]\u001b[A\n"," 40%|████      | 4/10 [00:16<00:20,  3.46s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:24<00:25,  5.12s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:25<00:14,  3.58s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:29<00:10,  3.66s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:29<00:05,  2.70s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:37<00:04,  4.18s/it]\u001b[A\n","100%|██████████| 10/10 [00:37<00:00,  3.80s/it]\n","100%|██████████| 80/80 [19:38<00:00, 14.73s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 of 5\n"]},{"output_type":"stream","name":"stderr","text":[" 49%|████▉     | 39/80 [06:53<07:08, 10.45s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:11<01:40, 11.15s/it]\u001b[A\n"," 20%|██        | 2/10 [00:11<00:39,  4.93s/it]\u001b[A\n"," 30%|███       | 3/10 [00:21<00:50,  7.26s/it]\u001b[A\n"," 40%|████      | 4/10 [00:22<00:27,  4.65s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:33<00:34,  6.99s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:34<00:19,  4.84s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:39<00:14,  4.91s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:39<00:07,  3.57s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:48<00:05,  5.11s/it]\u001b[A\n","100%|██████████| 10/10 [00:49<00:00,  4.91s/it]\n"," 99%|█████████▉| 79/80 [12:57<00:09,  9.37s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:08<01:15,  8.33s/it]\u001b[A\n"," 20%|██        | 2/10 [00:08<00:30,  3.82s/it]\u001b[A\n"," 30%|███       | 3/10 [00:15<00:36,  5.23s/it]\u001b[A\n"," 40%|████      | 4/10 [00:16<00:20,  3.41s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:24<00:24,  4.98s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:24<00:14,  3.50s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:28<00:10,  3.47s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:28<00:05,  2.55s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:36<00:04,  4.06s/it]\u001b[A\n","100%|██████████| 10/10 [00:36<00:00,  3.69s/it]\n","100%|██████████| 80/80 [13:34<00:00, 10.18s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4 of 5\n"]},{"output_type":"stream","name":"stderr","text":[" 49%|████▉     | 39/80 [05:02<04:25,  6.47s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:11<01:43, 11.46s/it]\u001b[A\n"," 20%|██        | 2/10 [00:12<00:43,  5.38s/it]\u001b[A\n"," 30%|███       | 3/10 [00:21<00:48,  6.96s/it]\u001b[A\n"," 40%|████      | 4/10 [00:22<00:26,  4.45s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:31<00:31,  6.34s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:32<00:17,  4.40s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:37<00:13,  4.59s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:38<00:06,  3.35s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:45<00:04,  4.65s/it]\u001b[A\n","100%|██████████| 10/10 [00:46<00:00,  4.61s/it]\n"," 99%|█████████▉| 79/80 [10:06<00:06,  6.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:08<01:13,  8.13s/it]\u001b[A\n"," 20%|██        | 2/10 [00:08<00:29,  3.69s/it]\u001b[A\n"," 30%|███       | 3/10 [00:15<00:35,  5.13s/it]\u001b[A\n"," 40%|████      | 4/10 [00:16<00:20,  3.36s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:23<00:24,  4.95s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:24<00:13,  3.49s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:27<00:10,  3.43s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:28<00:05,  2.53s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:35<00:03,  3.98s/it]\u001b[A\n","100%|██████████| 10/10 [00:36<00:00,  3.63s/it]\n","100%|██████████| 80/80 [10:43<00:00,  8.04s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5 of 5\n"]},{"output_type":"stream","name":"stderr","text":[" 49%|████▉     | 39/80 [04:15<04:29,  6.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:13<01:59, 13.28s/it]\u001b[A\n"," 20%|██        | 2/10 [00:14<00:47,  5.90s/it]\u001b[A\n"," 30%|███       | 3/10 [00:25<00:58,  8.35s/it]\u001b[A\n"," 40%|████      | 4/10 [00:25<00:31,  5.32s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:36<00:36,  7.23s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:37<00:19,  4.98s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:41<00:13,  4.65s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:41<00:06,  3.37s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:48<00:04,  4.50s/it]\u001b[A\n","100%|██████████| 10/10 [00:49<00:00,  4.94s/it]\n"," 99%|█████████▉| 79/80 [08:48<00:05,  5.98s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:08<01:12,  8.07s/it]\u001b[A\n"," 20%|██        | 2/10 [00:08<00:29,  3.70s/it]\u001b[A\n"," 30%|███       | 3/10 [00:15<00:35,  5.09s/it]\u001b[A\n"," 40%|████      | 4/10 [00:16<00:19,  3.31s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:23<00:24,  4.97s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:24<00:13,  3.49s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:27<00:10,  3.45s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:28<00:05,  2.54s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:35<00:03,  4.00s/it]\u001b[A\n","100%|██████████| 10/10 [00:36<00:00,  3.63s/it]\n","100%|██████████| 80/80 [09:24<00:00,  7.06s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Finished Training\n","Final model saved\n","Testing model\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [00:39<00:00,  3.91s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Calculating performance metrics\n","Plotting confusion matrix in /content/drive/MyDrive/Dissertation/skin_lesion_data/skin_lesion_part_1_models/2022-06-17_13-17-08.656016/densenet_confusion_matrix.png\n","Calculating\n","Done\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.004 MB of 0.005 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.727814…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3a372cee97c48c2b26bad7bc3fa4a20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/bal_acc</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test_classes/accuracy</td><td>▁</td></tr><tr><td>train/bce_logits_loss</td><td>█▅▂▂▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>train/custom_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/lr</td><td>███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val/accuracy</td><td>██▁▁▃▃▅▆▇█</td></tr><tr><td>val/balanced_acc</td><td>▁▅▄██▆▇███</td></tr><tr><td>val/custom_step</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>val/f1</td><td>▁▂▁▄▂▆▅▆██</td></tr><tr><td>val/loss</td><td>▅█▁▂▄▇▁▂▆▄▂▃▅▄▂▇▆▅▂▆▅▄▂▇▅▅▂▆▄▅▂▅▄▅▂▅▄▅▁▅</td></tr><tr><td>val/precision</td><td>▁█▆▅▅▆▆▆▇▇</td></tr><tr><td>val/recall</td><td>▁▅▄██▆▇███</td></tr><tr><td>val_classes/accuracy</td><td>██▁▁▃▃▅▆▇█</td></tr><tr><td>val_classes/custom_step</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test/accuracy</td><td>0.59866</td></tr><tr><td>test/bal_acc</td><td>0.61115</td></tr><tr><td>test/f1</td><td>0.44926</td></tr><tr><td>test/precision</td><td>0.41323</td></tr><tr><td>test/recall</td><td>0.61115</td></tr><tr><td>test_classes/accuracy</td><td>0.59866</td></tr><tr><td>train/bce_logits_loss</td><td>1.23529</td></tr><tr><td>train/custom_step</td><td>400</td></tr><tr><td>train/lr</td><td>0.0</td></tr><tr><td>val/accuracy</td><td>0.61153</td></tr><tr><td>val/balanced_acc</td><td>0.57603</td></tr><tr><td>val/custom_step</td><td>400</td></tr><tr><td>val/f1</td><td>0.44299</td></tr><tr><td>val/loss</td><td>1.3303</td></tr><tr><td>val/precision</td><td>0.41501</td></tr><tr><td>val/recall</td><td>0.57603</td></tr><tr><td>val_classes/accuracy</td><td>0.61153</td></tr><tr><td>val_classes/custom_step</td><td>400</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">wobbly-sponge-177</strong>: <a href=\"https://wandb.ai/sarahlouise/part_1_skin_lesion/runs/25fhy4fr\" target=\"_blank\">https://wandb.ai/sarahlouise/part_1_skin_lesion/runs/25fhy4fr</a><br/>Synced 5 W&B file(s), 2 media file(s), 2 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20220617_131710-25fhy4fr/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 1440x1440 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["#from part_2 import run\n","#percentage_intervals = np.arange(0.1, 1, 0.1).tolist()\n","\n","#for x in percentage_intervals:\n","conf = {\n","    \"epochs\": 5,\n","    \"batch_size\": 256,\n","    \"lr\": 1e-2,\n","    \"name\": \"densenet\",\n","    \"model\": \"densenet\",\n","    \"use_wandb\": True,\n","    \"use_amsgrad\": True,\n","    \"use_warm_restarts\": False,\n","    \"use_weighted_loss\": False,\n","    \"data_path\": \"/content/drive/MyDrive/Dissertation/skin_lesion_data/ISIC_2019_v2_prepro\",\n","    \"use_imbalanced_sampler\": True,\n","    \"use_custom_imbalanced_sampler\": False,\n","    \"use_RandomImbalancedDatasetSampler\":False,\n","    \"WorstCustomImbalancedDatasetSampler\": False,\n","    \"ClassBasedCustomImbalancedDatasetSampler\": False,\n","    \"ClassBasedRandomImbalancedDatasetSampler\": False,\n","    \"ClassBasedWorstImbalancedDatasetSampler\": False,\n","    #\"percent_keep\": round(x, 1),\n","    # \"use_pretrained\": \"/content/drive/MyDrive/Dissertation/skin_lesion_data/skin_lesion_part_1_models/2022-05-27_23-23-02.393905/densenet-final.pth\",\n","}\n","run(conf)\n","\n","\n","# all_configs = [\n","#             {\n","#         \"epochs\": 5,\n","#         \"batch_size\": 256,\n","#         \"lr\": 1e-2,\n","#         \"name\": \"densenet\",\n","#         \"model\": \"densenet\",\n","#         \"use_wandb\": True,\n","#         \"use_amsgrad\": True,\n","#         \"use_warm_restarts\": False,\n","#         \"use_weighted_loss\": False,\n","#         \"data_path\": \"/content/drive/MyDrive/Dissertation/skin_lesion_data/ISIC_2019_v2_prepro\",\n","#         \"use_imbalanced_sampler\": False,\n","#         \"use_custom_imbalanced_sampler\": True,\n","#         \"top_percent_keep\": 0.1,\n","#         #\"use_pretrained\": \"/content/drive/MyDrive/Dissertation/skin_lesion_data/skin_lesion_part_1_models/2022-05-17_21-00-07.965720/densenet-final.pth\",\n","#     },\n","    \n","# ]\n","\n","# # for config in all_configs:\n","# #     run(config)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"bias_binary_model.ipynb","provenance":[],"background_execution":"on","mount_file_id":"1MGy-NJAA8g75KYbGheTqnoQzj9Rl4iB4","authorship_tag":"ABX9TyMSF6+eN16Pst4c8DKExIbw"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e3a372cee97c48c2b26bad7bc3fa4a20":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_01313ed54f4a469f9c62c5708ec55fb5","IPY_MODEL_b89f20c681a44f6a97ef55fba5a99f3e"],"layout":"IPY_MODEL_c79e528f19db4c9c93a5a9b1b8f542d4"}},"01313ed54f4a469f9c62c5708ec55fb5":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_285688636bd04fefa3b919aed2b2aa8a","placeholder":"​","style":"IPY_MODEL_673502cf24044b4080322978fe488439","value":"0.021 MB of 0.021 MB uploaded (0.000 MB deduped)\r"}},"b89f20c681a44f6a97ef55fba5a99f3e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_aac4a1d0c70d44b3a56f5be195ca7189","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ffa9428d16ff41528f1786674d7282ca","value":1}},"c79e528f19db4c9c93a5a9b1b8f542d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"285688636bd04fefa3b919aed2b2aa8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"673502cf24044b4080322978fe488439":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aac4a1d0c70d44b3a56f5be195ca7189":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffa9428d16ff41528f1786674d7282ca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}