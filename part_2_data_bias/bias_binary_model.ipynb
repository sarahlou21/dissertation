{"cells":[{"cell_type":"markdown","source":["# Binary-class classification\n","\n","This file uses the same structure as used in the multi-class classification file.\n","\n","This file contains a binary classification model and uses image data from a pre-organised file which contains two folders for the two classes, NON-MEL and MEL. \n","\n","This file also contains a custom image sampler that allows for different ratios of female:male images to be sampled, for the equal numbers of 6000:6000 and the 1:5 ratio with 2000:10000 images."],"metadata":{"id":"LhhYJbVTlZRI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"opp4Cld9gck7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656440792558,"user_tz":-60,"elapsed":11518,"user":{"displayName":"Sarah-Louise Hayes","userId":"13751648430878105914"}},"outputId":"cd207fe9-05d5-44e4-e4b2-6c271ad45a58"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (7.34.0)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython) (4.8.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython) (57.4.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython) (5.1.1)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython) (0.18.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython) (4.4.2)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from ipython) (0.1.3)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython) (0.7.5)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython) (2.6.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython) (3.0.30)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.5)\n","Using device cuda:0\n"]},{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f6b61971350>"]},"metadata":{},"execution_count":22}],"source":["!pip install -U ipython\n","!pip install -r /content/drive/MyDrive/Dissertation/requirements.txt -qqq\n","!pip install ipdb -qqq\n","\n","\n","from datetime import datetime\n","import json\n","import torch\n","import torchvision\n","import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","import os\n","import numpy as np\n","import torchvision.models as models\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch import argmax\n","from tqdm import tqdm\n","from PIL import Image\n","from matplotlib import pyplot as plt\n","import seaborn as sn\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score, f1_score, classification_report, balanced_accuracy_score\n",")\n","from torchsampler import ImbalancedDatasetSampler\n","import wandb\n","import numpy as np\n","from os import listdir\n","from os.path import join, isdir\n","from glob import glob\n","import cv2\n","import timeit\n","import timm\n","from sklearn.metrics import confusion_matrix\n","from torchvision.datasets import ImageFolder\n","from collections import Counter\n","from sklearn.utils import class_weight\n","from torchvision.transforms import AutoAugment\n","from operator import itemgetter\n","import random\n","\n","from torchvision.transforms.autoaugment import AutoAugmentPolicy\n","\n","#changing the device to GPU rather than CPU if it is available,\n","# this will decrease model training time.\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device {}\".format(device))\n","\n","torch.manual_seed(17)"]},{"cell_type":"code","source":["class ImageResize(object):\n","        \"\"\"\n","        PIL's resize performs better than pytorch\n","        https://blog.zuru.tech/machine-learning/2021/08/09/the-dangers-behind-image-resizing\n","        \"\"\"\n","\n","        def __init__(self, new_h, new_w):\n","            self.new_h = new_h\n","            self.new_w = new_w\n","\n","        def __call__(self, image):\n","            image = image.resize((self.new_w, self.new_h), resample=Image.BILINEAR)\n","            return image"],"metadata":{"id":"OqY5UiOBX5sG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BinaryClassBasedCustomImbalancedDatasetSampler(ImbalancedDatasetSampler):\n","    def __init__(self, dataset, callback_get_label, male_count, female_count, path_meta_data):\n","        # mess with dataset\n","        total_meta_data = pd.read_csv(path_meta_data)\n","\n","        total_meta_data[\"class_id\"] = [None] * len(total_meta_data)\n","        for img_path, class_id in zip(dataset.imgs, dataset.targets):\n","            image_id = img_path[0].split(\"/\")[-1].split(\".\")[0]\n","            total_meta_data.loc[total_meta_data[\"image\"] == image_id, \"class_id\"] = class_id\n","\n","        train_metadata = total_meta_data.groupby(\"rand_split\").get_group(\"train\")\n","\n","        sex_group = train_metadata.groupby(\"sex\")\n","        male_df = sex_group.get_group(\"male\").sample(n=male_count)\n","        female_df = sex_group.get_group(\"female\").sample(n=female_count)\n","\n","        filtered_dataset_names = pd.concat([male_df, female_df]).get([\n","            \"image_path\", \"class_id\"\n","        ]).values\n","\n","        dataset.imgs = filtered_dataset_names \n","        # pass back up\n","        dataset.targets = [x[1] for x in dataset.imgs]\n","        dataset.samples = dataset.imgs\n","        super().__init__(dataset=dataset, callback_get_label=callback_get_label)"],"metadata":{"id":"XSkBuT1bBuSh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZeVHonwolOyZ"},"source":["## Network generation\n","\n","Five networks were created using several architectures loaded from the Pytroch library.  Within each model-specific function, the feature extraction layers have been frozen and the final classification layer unfrozen, to allow this final layer to train on our Lesion dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bxMWZ9CIlK7B"},"outputs":[],"source":["def create_network_densenet():\n","        net = models.densenet161(pretrained=True)\n","        net.classifier = nn.Linear(in_features=2208, out_features=2, bias=True)\n","\n","        for param in net.parameters():\n","                param.requires_grad = False\n","        for param in net.classifier.parameters():\n","                param.requires_grad = True\n","\n","        return net\n"]},{"cell_type":"code","source":["class ImageFolderWithPaths(ImageFolder):\n","\n","    def __getitem__(self, index: int):\n","        path, target = self.samples[index]\n","        sample = self.loader(path)\n","        if self.transform is not None:\n","            sample = self.transform(sample)\n","        if self.target_transform is not None:\n","            target = self.target_transform(target)\n","\n","        return sample, target, path"],"metadata":{"id":"FYQuy_tlq9BV"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xDTi6y0Uk7N9"},"outputs":[],"source":["def run(config):  \n","    torch.manual_seed(17)\n","    BASE_PATH = '/content/drive/MyDrive/Dissertation/skin_lesion_data/skin_lesion_part_2_models/'\n","    now = str(datetime.now()).replace(\":\", \"-\").replace(\" \", \"_\")\n","    RESULTS_PATH = os.path.join(BASE_PATH, now)\n","    os.makedirs(RESULTS_PATH, exist_ok=False)\n","\n","    with open(os.path.join(RESULTS_PATH, \"config.json\"), \"w\") as f:\n","        json.dump(config, f, indent=4)\n","\n","    if config.get(\"use_wandb\"):\n","        # this integrates the third-party platform, Weights and Biases,\n","        # with this notebook.\n","        run = wandb.init(\n","            project=\"part_2_skin_lesion\",\n","            entity=\"sarahlouise\",\n","            config=config,\n","        )\n","\n","    batch_size = config[\"batch_size\"]\n","    Imagenet_NV = ((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","\n","    print(\"Configuring datasets\")\n","    trainset = ImageFolder(\n","        os.path.join(config.get(\"data_path\"), 'train'),\n","        transform=transforms.Compose([\n","                            transforms.RandomVerticalFlip(0.5),\n","                            transforms.RandomHorizontalFlip(0.5),\n","                            transforms.RandomApply(nn.ModuleList([transforms.RandomRotation(degrees=(0, 360))]), p=0.2),\n","                            ImageResize(224,224),\n","                            transforms.PILToTensor(),\n","                            transforms.ConvertImageDtype(torch.float),\n","                            transforms.Normalize(*Imagenet_NV),\n","                        ])\n","        )\n","    \n","    imbalanced_sampler_choice = [\n","        config.get(\"use_binary_gender_custom_imbalanced_sampler\"),\n","        config.get(\"use_imbalanced_sampler\"),\n","    ]\n","    if imbalanced_sampler_choice.count(True) > 1:\n","        raise ValueError(\"Pick one sampler only\")\n","\n","    elif config.get(\"use_binary_gender_custom_imbalanced_sampler\"):\n","        sampler = BinaryClassBasedCustomImbalancedDatasetSampler(\n","            dataset=trainset,\n","            callback_get_label=lambda x: x.targets,\n","            male_count=config.get(\"male_count\"),\n","            female_count=config.get(\"female_count\"),\n","            path_meta_data=config.get(\"path_meta_data\"),\n","        )\n","        shuffle = False\n","    elif config.get(\"use_imbalanced_sampler\"):\n","        sampler = ImbalancedDatasetSampler(\n","            trainset,\n","            callback_get_label=lambda x: x.targets,\n","        )\n","        shuffle = False\n","    else:\n","        sampler = None\n","        shuffle = True\n","\n","    trainloader = torch.utils.data.DataLoader(\n","        trainset,\n","        batch_size=batch_size,\n","        num_workers=2,\n","        sampler=ImbalancedDatasetSampler(\n","            trainset,\n","            callback_get_label=lambda x: x.targets\n","    ))\n","\n","    valset = ImageFolder(\n","        os.path.join(config.get(\"data_path\"), 'val'),\n","        transform=transforms.Compose([\n","                            ImageResize(224,224),\n","                            transforms.PILToTensor(),\n","                            transforms.ConvertImageDtype(torch.float),\n","                            transforms.Normalize(*Imagenet_NV),\n","                        ]))\n","\n","    valloader = torch.utils.data.DataLoader(\n","        valset,\n","        batch_size=batch_size,\n","        shuffle=False,\n","        num_workers=2\n","    )\n","\n","    testset = ImageFolderWithPaths(\n","        os.path.join(config.get(\"data_path\"), 'test'),\n","        transform=transforms.Compose([\n","                                ImageResize(224,224),\n","                                transforms.PILToTensor(),\n","                                transforms.ConvertImageDtype(torch.float),\n","                                transforms.Normalize(*Imagenet_NV),\n","                            ]))\n","\n","    testloader = torch.utils.data.DataLoader(\n","        testset,\n","        batch_size=batch_size,\n","        shuffle=False,\n","        num_workers=2\n","    )\n","    \n","    classes = sorted(os.listdir(os.path.join(config.get(\"data_path\"), 'train')))\n","\n","    if config.get(\"use_wandb\"):\n","        wandb.sklearn.plot_class_proportions(\n","            trainset.targets,\n","            testset.targets,\n","            classes\n","        )\n","\n","\n","    net = create_network_densenet()\n","    print(f\"Moving network to {device}\")\n","    net = net.to(device)\n","\n","    # ## Training configurations\n","    \n","    # defining the training configurations\n","    no_of_epochs = config[\"epochs\"]\n","    \n","    # calculating class weights\n","\n","    labels = np.array(trainset.targets)\n","    criterion = nn.CrossEntropyLoss().to(device)\n","\n","    optimizer = optim.Adam(\n","        net.parameters(),\n","        lr=config[\"lr\"],\n","        amsgrad=config[\"use_amsgrad\"]\n","    )\n","\n","    scheduler = optim.lr_scheduler.CosineAnnealingLR(\n","        optimizer,\n","        round((len(trainset)/batch_size)*no_of_epochs)\n","        )\n","\n","\n","    # ##  Model training\n","    #\n","    # This section included the training for the model. The network was set to train, a mini-batch was passed through the model and then the loss was then backpropagated. Each trained model was also automatically saved.\n","\n","    if config.get(\"use_wandb\"):\n","        wandb.watch(net)\n","\n","    if not config.get(\"use_pretrained\"):\n","        print(\"Starting training\")\n","        for epoch in range(no_of_epochs):  # loop over the dataset multiple times\n","            print(\"Epoch {} of {}\".format(epoch+1, no_of_epochs))\n","            epoch_running_loss = []\n","            epoch_val_metric = []\n","            for i, data in tqdm(enumerate(trainloader, 1), total=len(trainloader)):\n","                current_step = (len(trainloader) * epoch) + i\n","                \n","                # get the inputs; data is a list of [inputs, labels]\n","                net.train()\n","                \n","                inputs, labels = data\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","                \n","                # forward + backward\n","                outputs = net(inputs)\n","\n","                \n","                # outputs = torch.max(outputs, 1)\n","                loss = criterion(outputs, labels)\n","                \n","                loss.backward()\n","                optimizer.step()\n","                scheduler.step()\n","\n","                # saving loss statistics\n","                loss_val = loss.item()\n","                if config.get(\"use_wandb\"):\n","                    wandb.log(\n","                        {\n","                            \"train/bce_logits_loss\": loss_val,\n","                            \"train/lr\": scheduler.get_last_lr()[0],\n","                            \"train/custom_step\": (len(trainloader) * epoch) + i,\n","                        }\n","                    )\n","\n","                # adding in valiation data testing\n","                if i % round(40*config.get(\"percent_keep\", 1)) == 0:\n","                    model_name = \"{name}-epoch-{epoch}-step-{step}.pth\".format(\n","                        name=config[\"name\"],\n","                        epoch=epoch,\n","                        step=i,\n","                    )\n","                    model_path = os.path.join(RESULTS_PATH, model_name)\n","                    # Commenting out to save space\n","                    # torch.save(net.state_dict(), model_path)\n","\n","                    predicted = []\n","                    actual = []\n","\n","                    print(\"Running validation\")\n","                    net.eval()\n","                    with torch.no_grad():\n","                        for i, data in enumerate(tqdm(valloader, total=len(valloader))):\n","                            inputs, labels = data\n","                            inputs = inputs.to(device)\n","                            labels = labels.to(device)\n","\n","                            outputs = net(inputs)\n","                            loss = criterion(outputs, labels)\n","                            if config.get(\"use_wandb\"):\n","                                wandb.log({\n","                                    \"val/loss\": loss,\n","                                    \"val/custom_step\": current_step,\n","                                })\n","\n","                            # collect the correct predictions for each class\n","                            actual.extend(labels.detach().cpu().numpy())\n","                            predicted.extend(torch.argmax(outputs, 1).detach().cpu().numpy())\n","\n","                        mb_acc = accuracy_score(actual, predicted)\n","                        precision = precision_score(actual, predicted, average=\"macro\", zero_division = 1)\n","                        recall = recall_score(actual, predicted, average=\"macro\", zero_division = 1)\n","                        f1 = f1_score(actual, predicted, average=\"macro\", zero_division = 1)\n","                        bal_acc = balanced_accuracy_score(actual, predicted)\n","                        metric_report = classification_report(\n","                            np.array(actual),\n","                            np.array(predicted),\n","                            output_dict=True,\n","                            zero_division=1,\n","                        )\n","                        metric_report = {\n","                            f\"val_classes/{k}\": v\n","                            for k, v in metric_report.items()\n","                        }\n","                        metric_report.update({\n","                            \"val_classes/custom_step\": current_step,\n","                        })\n","\n","                        if config.get(\"use_wandb\"):\n","                            wandb.log({\n","                                \"val/accuracy\": mb_acc,\n","                                \"val/precision\": precision,\n","                                \"val/recall\": recall,\n","                                \"val/f1\": f1,\n","                                \"val/balanced_acc\": bal_acc,\n","                                \"val/custom_step\": current_step\n","                            })\n","                            wandb.log(metric_report)\n","\n","\n","\n","        print('Finished Training')\n","        # saving each trained model\n","        model_name = '{}-final.pth'.format(\n","            config[\"name\"]\n","        )\n","        model_path = os.path.join(RESULTS_PATH, model_name)\n","        torch.save(net.state_dict(), model_path)\n","\n","        print(\"Final model saved\")\n","\n","    # ##  Model testing\n","    #\n","    # The model was set to evaluate mode for testing. The predicted and actual results were saved, and used for generating a confusion matrix and metrics.\n","    #\n","    # A confusion matrix was generated, showing the number of true positives and negatives, and false positives and negatives. Additionally, the metrics were calculated, including the accuracy score, precision and recall. The corresponding graphs were created using Weights and Biases.\n","\n","\n","    if config.get(\"use_pretrained\"):\n","        net.load_state_dict(\n","            torch.load(\n","                config.get(\"use_pretrained\")\n","            )\n","        )\n","\n","    predicted = []\n","    actual = []\n","    image_paths = []\n","    \n","    print(\"Testing model\")\n","    # again no gradients needed\n","    net.eval()\n","    with torch.no_grad():\n","        for i, data in enumerate(tqdm(testloader, total=len(testloader))):\n","            inputs, labels, paths = data\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            outputs = net(inputs)\n","            actual.extend(labels.detach().cpu().numpy())\n","            predicted.extend(torch.argmax(outputs, 1).detach().cpu().numpy())\n","            image_paths.extend(paths)\n","\n","\n","    results = pd.DataFrame.from_dict(\n","        {\n","            \"predicted\": predicted,\n","            \"actual\": actual,\n","            \"image_path\": image_paths\n","        }\n","    )\n","    results.to_csv(os.path.join(RESULTS_PATH, \"each_image_predictions.csv\"))\n","\n","\n","    print(\"Calculating performance metrics\")\n","    model_accuracy = accuracy_score(actual, predicted)\n","    model_precision = precision = precision_score(actual, predicted,\n","                                                average=\"macro\", zero_division = 1)\n","    model_recall = recall_score(actual, predicted,\n","                                average=\"macro\", zero_division = 1)\n","    model_f1 = f1_score(actual, predicted, average=\"macro\", zero_division = 1)\n","    model_bal_acc = balanced_accuracy_score(actual, predicted)\n","    metric_report = classification_report(\n","        np.array(actual),\n","        np.array(predicted),\n","        output_dict=True,\n","        zero_division=1,\n","    )\n","    metric_report = {\n","        f\"test_classes/{k}\": v\n","        for k, v in metric_report.items()\n","    }\n","\n","    if config.get(\"use_wandb\"):\n","        wandb.log({\"test/accuracy\": model_accuracy})\n","        wandb.log({\"test/precision\": model_precision})\n","        wandb.log({\"test/recall\": model_recall})\n","        wandb.log({\"test/f1\": model_f1})\n","        wandb.log({\"test/bal_acc\": model_bal_acc})\n","        wandb.sklearn.plot_confusion_matrix(actual, predicted, classes, normalize=\"true\")\n","        wandb.log(metric_report)\n","    else:\n","        print(\"test/accuracy\", model_accuracy)\n","        print(\"test/precision\", model_precision)\n","        print(\"test/recall\", model_recall)\n","        print(\"test/f1\", model_f1)\n","        print(\"test/bal_acc\", model_bal_acc)\n","\n","    plot_save_path = os.path.join(RESULTS_PATH, '{}_confusion_matrix.png'.format(\n","        config[\"name\"]\n","    ))\n","    print(\"Plotting confusion matrix in {}\".format(plot_save_path))\n","\n","    print(\"Calculating\")\n","    conf_matrix = confusion_matrix(y_true=actual, y_pred=predicted, normalize=\"true\")\n","    print(\"Done\")\n","    fig =plt.figure(figsize=(20, 20))\n","    ax = fig.add_subplot(1,1,1)\n","    ax.matshow(conf_matrix, cmap=plt.cm.Reds)\n","\n","\n","    plt.xlabel('Predictions')\n","    plt.ylabel('Actuals')\n","    plt.title('Confusion Matrix')\n","    plt.savefig(plot_save_path)\n","    # plt.show()\n","\n","    if config.get(\"use_wandb\"):\n","        run.finish()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xjSeEY5BUdey","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["74ad4ea3e2a9489fa46a2958b38e954e","9e0d1cf0631b49d795983b4e1dd3109d","bf4adf1e48634402af4311f8de380307","82e33364e3ce4061af6ce7710b2271bf","5fc795880e1e46dc9e4e49d682b80f8e","fcd988927fa4404e81851d67f53c79e2","a394dba59cba46a6841eca6188f49413","0f26f04cf1a74538a6c862c47ba8babe"]},"outputId":"51d2534b-b961-410c-8b78-35dde14a438e","executionInfo":{"status":"ok","timestamp":1656443073151,"user_tz":-60,"elapsed":2280646,"user":{"displayName":"Sarah-Louise Hayes","userId":"13751648430878105914"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msarahlouise\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.12.19"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20220628_182631-337lcf5q</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/sarahlouise/part_2_skin_lesion/runs/337lcf5q\" target=\"_blank\">proud-field-17</a></strong> to <a href=\"https://wandb.ai/sarahlouise/part_2_skin_lesion\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Configuring datasets\n","Moving network to cuda:0\n","Starting training\n","Epoch 1 of 5\n"]},{"output_type":"stream","name":"stderr","text":[" 83%|████████▎ | 39/47 [12:15<01:46, 13.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:10<01:31, 10.16s/it]\u001b[A\n"," 20%|██        | 2/10 [00:13<00:48,  6.02s/it]\u001b[A\n"," 30%|███       | 3/10 [00:18<00:39,  5.70s/it]\u001b[A\n"," 40%|████      | 4/10 [00:19<00:22,  3.71s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:24<00:20,  4.12s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:24<00:11,  2.94s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:35<00:16,  5.58s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:36<00:08,  4.14s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:48<00:06,  6.47s/it]\u001b[A\n","100%|██████████| 10/10 [00:49<00:00,  4.90s/it]\n","100%|██████████| 47/47 [13:56<00:00, 17.79s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 of 5\n"]},{"output_type":"stream","name":"stderr","text":["\n"," 83%|████████▎ | 39/47 [06:02<01:13,  9.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:10<01:37, 10.80s/it]\u001b[A\n"," 20%|██        | 2/10 [00:14<00:51,  6.44s/it]\u001b[A\n"," 30%|███       | 3/10 [00:20<00:43,  6.15s/it]\u001b[A\n"," 40%|████      | 4/10 [00:20<00:23,  4.00s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:26<00:22,  4.58s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:26<00:12,  3.24s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:38<00:17,  5.92s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:39<00:09,  4.54s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:49<00:06,  6.22s/it]\u001b[A\n","100%|██████████| 10/10 [00:50<00:00,  5.05s/it]\n","100%|██████████| 47/47 [07:18<00:00,  9.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 of 5\n"]},{"output_type":"stream","name":"stderr","text":["\n"," 83%|████████▎ | 39/47 [04:27<00:50,  6.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:11<01:40, 11.13s/it]\u001b[A\n"," 20%|██        | 2/10 [00:14<00:53,  6.74s/it]\u001b[A\n"," 30%|███       | 3/10 [00:22<00:48,  6.98s/it]\u001b[A\n"," 40%|████      | 4/10 [00:22<00:27,  4.51s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:29<00:25,  5.16s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:29<00:14,  3.65s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:40<00:18,  6.02s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:42<00:09,  4.76s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:51<00:05,  5.90s/it]\u001b[A\n","100%|██████████| 10/10 [00:51<00:00,  5.18s/it]\n","100%|██████████| 47/47 [05:39<00:00,  7.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 4 of 5\n"]},{"output_type":"stream","name":"stderr","text":["\n"," 83%|████████▎ | 39/47 [03:37<00:41,  5.24s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:12<01:54, 12.77s/it]\u001b[A\n"," 20%|██        | 2/10 [00:16<01:00,  7.57s/it]\u001b[A\n"," 30%|███       | 3/10 [00:22<00:48,  6.97s/it]\u001b[A\n"," 40%|████      | 4/10 [00:23<00:26,  4.48s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:29<00:24,  4.87s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:29<00:13,  3.44s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:38<00:15,  5.12s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:40<00:08,  4.02s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:48<00:05,  5.35s/it]\u001b[A\n","100%|██████████| 10/10 [00:48<00:00,  4.90s/it]\n","100%|██████████| 47/47 [04:48<00:00,  6.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 5 of 5\n"]},{"output_type":"stream","name":"stderr","text":["\n"," 83%|████████▎ | 39/47 [03:16<00:44,  5.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:13<01:58, 13.19s/it]\u001b[A\n"," 20%|██        | 2/10 [00:18<01:07,  8.46s/it]\u001b[A\n"," 30%|███       | 3/10 [00:25<00:54,  7.77s/it]\u001b[A\n"," 40%|████      | 4/10 [00:25<00:29,  4.95s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:31<00:25,  5.04s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:31<00:14,  3.56s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:39<00:15,  5.04s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:41<00:08,  4.01s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:49<00:05,  5.29s/it]\u001b[A\n","100%|██████████| 10/10 [00:50<00:00,  5.04s/it]\n","100%|██████████| 47/47 [04:22<00:00,  5.58s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Finished Training\n","Final model saved\n","Testing model\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [00:41<00:00,  4.17s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Calculating performance metrics\n","Plotting confusion matrix in /content/drive/MyDrive/Dissertation/skin_lesion_data/skin_lesion_part_2_models/2022-06-28_18-26-31.230005/densenet_confusion_matrix.png\n","Calculating\n","Done\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.926963…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74ad4ea3e2a9489fa46a2958b38e954e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/bal_acc</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test_classes/accuracy</td><td>▁</td></tr><tr><td>train/bce_logits_loss</td><td>▂█▂▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/custom_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/lr</td><td>███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val/accuracy</td><td>▇█▁▆▅</td></tr><tr><td>val/balanced_acc</td><td>▁▆▆██</td></tr><tr><td>val/custom_step</td><td>▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆████████</td></tr><tr><td>val/f1</td><td>▆█▁▇▆</td></tr><tr><td>val/loss</td><td>█▄▃▁▂▃▄▄▆▄▃▁▂▃▄▄▄▃▄▂▄▅▆▆▅▄▄▂▃▄▄▄▅▃▄▂▃▄▅▅</td></tr><tr><td>val/precision</td><td>▅█▁▆▅</td></tr><tr><td>val/recall</td><td>▁▆▆██</td></tr><tr><td>val_classes/accuracy</td><td>▇█▁▆▅</td></tr><tr><td>val_classes/custom_step</td><td>▁▃▅▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test/accuracy</td><td>0.76204</td></tr><tr><td>test/bal_acc</td><td>0.75126</td></tr><tr><td>test/f1</td><td>0.68272</td></tr><tr><td>test/precision</td><td>0.66878</td></tr><tr><td>test/recall</td><td>0.75126</td></tr><tr><td>test_classes/accuracy</td><td>0.76204</td></tr><tr><td>train/bce_logits_loss</td><td>0.437</td></tr><tr><td>train/custom_step</td><td>235</td></tr><tr><td>train/lr</td><td>0.0</td></tr><tr><td>val/accuracy</td><td>0.77379</td></tr><tr><td>val/balanced_acc</td><td>0.75928</td></tr><tr><td>val/custom_step</td><td>228</td></tr><tr><td>val/f1</td><td>0.6939</td></tr><tr><td>val/loss</td><td>0.55345</td></tr><tr><td>val/precision</td><td>0.67749</td></tr><tr><td>val/recall</td><td>0.75928</td></tr><tr><td>val_classes/accuracy</td><td>0.77379</td></tr><tr><td>val_classes/custom_step</td><td>228</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">proud-field-17</strong>: <a href=\"https://wandb.ai/sarahlouise/part_2_skin_lesion/runs/337lcf5q\" target=\"_blank\">https://wandb.ai/sarahlouise/part_2_skin_lesion/runs/337lcf5q</a><br/>Synced 5 W&B file(s), 2 media file(s), 2 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20220628_182631-337lcf5q/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 1440x1440 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["#from part_2 import run\n","\n","conf = {\n","    \"epochs\": 5,\n","    \"batch_size\": 256,\n","    \"lr\": 1e-2,\n","    \"name\": \"densenet\",\n","    \"use_wandb\": True,\n","    \"use_amsgrad\": True,\n","    \"data_path\": \"/content/drive/MyDrive/Dissertation/skin_lesion_data/ISIC_2019_v2_prepro_binary\",\n","    \"use_imbalanced_sampler\": False,\n","    \"use_binary_gender_custom_imbalanced_sampler\": True,\n","    \"male_count\": 6000,\n","    \"female_count\": 6000,\n","    \"path_meta_data\": \"/content/drive/MyDrive/Dissertation/skin_lesion_data/mel_vs_nonmel.csv\",\n","}\n","run(conf)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"QBERPesRSZaE"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"bias_binary_model.ipynb","provenance":[],"background_execution":"on","mount_file_id":"1mChFP20JRc1SVMpBgK1zOHEwY33KIvHm","authorship_tag":"ABX9TyPHYGg5+lMfXGUEw9rLnNj9"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"74ad4ea3e2a9489fa46a2958b38e954e":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_9e0d1cf0631b49d795983b4e1dd3109d","IPY_MODEL_bf4adf1e48634402af4311f8de380307"],"layout":"IPY_MODEL_82e33364e3ce4061af6ce7710b2271bf"}},"9e0d1cf0631b49d795983b4e1dd3109d":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5fc795880e1e46dc9e4e49d682b80f8e","placeholder":"​","style":"IPY_MODEL_fcd988927fa4404e81851d67f53c79e2","value":"0.015 MB of 0.015 MB uploaded (0.000 MB deduped)\r"}},"bf4adf1e48634402af4311f8de380307":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a394dba59cba46a6841eca6188f49413","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0f26f04cf1a74538a6c862c47ba8babe","value":1}},"82e33364e3ce4061af6ce7710b2271bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fc795880e1e46dc9e4e49d682b80f8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcd988927fa4404e81851d67f53c79e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a394dba59cba46a6841eca6188f49413":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f26f04cf1a74538a6c862c47ba8babe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}