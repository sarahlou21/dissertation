{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27881,"status":"ok","timestamp":1652723737741,"user":{"displayName":"Sarah-Louise Hayes","userId":"13751648430878105914"},"user_tz":-60},"id":"opp4Cld9gck7","outputId":"0918f29b-2915-49ee-f86d-8243b44f8ebf"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     | 297 kB 209 kB/s\n","\u001b[K     |████████████████████████████████| 1.8 MB 3.7 MB/s \n","\u001b[K     |████████████████████████████████| 431 kB 20.8 MB/s \n","\u001b[K     |████████████████████████████████| 181 kB 51.8 MB/s \n","\u001b[K     |████████████████████████████████| 145 kB 48.1 MB/s \n","\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n","\u001b[?25h  Building wheel for torchsampler (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Using device cuda:0\n"]},{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f91a1ca1270>"]},"metadata":{},"execution_count":1}],"source":["!pip install -r /content/drive/MyDrive/Dissertation/requirements.txt -qqq\n","\n","\n","from datetime import datetime\n","import json\n","import torch\n","import torchvision\n","import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","import os\n","import numpy as np\n","import torchvision.models as models\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch import argmax\n","from tqdm import tqdm\n","from PIL import Image\n","from matplotlib import pyplot as plt\n","import seaborn as sn\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score, f1_score, classification_report\n",")\n","from torchsampler import ImbalancedDatasetSampler\n","import wandb\n","import numpy as np\n","from os import listdir\n","from os.path import join, isdir\n","from glob import glob\n","import cv2\n","import timeit\n","import timm\n","from sklearn.metrics import confusion_matrix\n","from torchvision.datasets import ImageFolder\n","from collections import Counter\n","from sklearn.utils import class_weight\n","\n","#changing the device to GPU rather than CPU if it is available,\n","# this will decrease model training time.\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device {}\".format(device))\n","\n","torch.manual_seed(17)\n"]},{"cell_type":"markdown","metadata":{"id":"-qLIgh8FkgiD"},"source":["Several custom classes were made. The first, ImageResize(), resizes an image using the PIL image resizer set to the bilinear function. A custom class was generated even though Pytorch has its own resizer, as discussed in the following article, https://blog.zuru.tech/machine-learning/2021/08/09/the-dangers-behind-image-resizing there are resizing issues associated with certain libraries such as Pytorch which introduce artefacts or don't provide sufficient antialiasing in the resized images using libraries such as Pytorch.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b9TywHjhgu2P"},"outputs":[],"source":["class ImageResize(object):\n","        \"\"\"\n","        PIL's resize performs better than pytorch\n","        https://blog.zuru.tech/machine-learning/2021/08/09/the-dangers-behind-image-resizing\n","        \"\"\"\n","\n","        def __init__(self, new_h, new_w):\n","            self.new_h = new_h\n","            self.new_w = new_w\n","\n","        def __call__(self, image):\n","            image = image.resize((self.new_w, self.new_h), resample=Image.BILINEAR)\n","            return image\n","\n","class HairRemoval(object):\n","        \"\"\"\n","        Hair removal code\n","        https://github.com/ThiruRJST/Melanoma_Classification \n","        \"\"\"\n","\n","        def __call__(self, image):\n","            # convert image to grayScale\n","            grayScale = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n","\n","            # kernel for morphologyEx\n","            kernel = cv2.getStructuringElement(1, (17, 17))\n","\n","            # apply MORPH_BLACKHAT to grayScale image\n","            blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n","\n","            # apply thresholding to blackhat\n","            _, threshold = cv2.threshold(blackhat, 10, 255, cv2.THRESH_BINARY)\n","\n","            # inpaint with original image and threshold image\n","            final_image = cv2.inpaint(image, threshold, 1, cv2.INPAINT_TELEA)\n","\n","            return final_image\n","\n","\n","class ShadesOfGrey(object):\n","        \"\"\"\n","        Code from https://github.com/ThiruRJST/Melanoma_Classification\n","        imgage (numpy array): the original image with format of (h, w, c)\n","        power (int): the degree of norm, 6 is used in reference paper\n","        gamma (float): the value of gamma correction, 2.2 is used in reference paper\n","        \"\"\"\n","\n","        def __init__(self, power=6, gamma=2.2):\n","            self.power = power\n","            self.gamma = gamma\n","\n","        def __call__(self, image):\n","            image_dtype = image.dtype\n","\n","            if self.gamma is not None:\n","                image = image.astype('uint8')\n","                look_up_table = np.ones((256, 1), dtype='uint8') * 0\n","                for i in range(256):\n","                    look_up_table[i][0] = 255 * pow(i / 255, 1 / self.gamma)\n","                image = cv2.LUT(image, look_up_table)\n","\n","            image = image.astype('float32')\n","            image_power = np.power(image, self.power)\n","            rgb_vec = np.power(np.mean(image_power, (0, 1)), 1 / self.power)\n","            rgb_norm = np.sqrt(np.sum(np.power(rgb_vec, 2.0)))\n","            rgb_vec = rgb_vec / rgb_norm\n","            rgb_vec = 1 / (rgb_vec * np.sqrt(3))\n","            image = np.multiply(image, rgb_vec)\n","\n","            # Andrew Anikin suggestion\n","            image = np.clip(image, a_min=0, a_max=255)\n","\n","            return image.astype(image_dtype)\n","    \n","class CropBlackCircle(object):\n","    \"\"\"\n","    https://stackoverflow.com/questions/61986407/crop-x-ray-image-to-remove-black-background \n","    \"\"\"\n","    def __call__(self, image):\n","        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","        # threshold \n","        thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n","        hh, ww = thresh.shape\n","\n","        # make bottom 2 rows black where they are white the full width of the image\n","        thresh[hh-3:hh, 0:ww] = 0\n","\n","        # get bounds of white pixels\n","        white = np.where(thresh==255)\n","        xmin, ymin, xmax, ymax = np.min(white[1]), np.min(white[0]), np.max(white[1]), np.max(white[0])\n","\n","        # crop the image at the bounds adding back the two blackened rows at the bottom\n","        crop = image[ymin:ymax+3, xmin:xmax]\n","\n","        return crop\n","\n","class Cutout_v0(object):\n","    \"\"\"Randomly mask out one or more patches from an image.\n","        Args:\n","            n_holes (int): Number of patches to cut out of each image.\n","            length (int): The length (in pixels) of each square patch.\n","        \"\"\"\n","        def __init__(self, n_holes, length):\n","            self.n_holes = n_holes\n","            self.length = length\n","\n","        def __call__(self, img):\n","            \"\"\"\n","            Args:\n","                img (Tensor): Tensor image of size (C, H, W).\n","            Returns:\n","                Tensor: Image with n_holes of dimension length x length cut out of it.\n","            \"\"\"\n","            img = np.array(img)\n","            #print(img.shape)\n","            h = img.shape[0]\n","            w = img.shape[1]\n","\n","            mask = np.ones((h, w), np.uint8)\n","\n","            for n in range(self.n_holes):\n","                y = np.random.randint(h)\n","                x = np.random.randint(w)\n","\n","                y1 = np.clip(y - self.length // 2, 0, h)\n","                y2 = np.clip(y + self.length // 2, 0, h)\n","                x1 = np.clip(x - self.length // 2, 0, w)\n","                x2 = np.clip(x + self.length // 2, 0, w)\n","\n","                mask[y1: y2, x1: x2] = 0.\n","\n","            #mask = torch.from_numpy(mask)\n","            #mask = mask.expand_as(img)\n","            img = img * np.expand_dims(mask,axis=2)\n","            img = Image.fromarray(img)\n","            \n","            return img  "]},{"cell_type":"markdown","metadata":{"id":"ZeVHonwolOyZ"},"source":["## Network generation\n","\n","Five networks were created using several architectures loaded from the Pytroch library.  Within each model-specific function, the feature extraction layers have been frozen and the final classification layer unfrozen, to allow this final layer to train on our Lesion dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bxMWZ9CIlK7B"},"outputs":[],"source":["def create_network_densenet():\n","        net = models.densenet161(pretrained=True)\n","        net.classifier = nn.Linear(in_features=2208, out_features=8, bias=True)\n","\n","        for param in net.parameters():\n","                param.requires_grad = False\n","        for param in net.classifier.parameters():\n","                param.requires_grad = True\n","\n","        return net\n","\n","\n","def create_network_efficientnet():\n","        net = models.efficientnet_b0(pretrained=True)\n","        net.classifier[1] = nn.Linear(in_features=1280, out_features=8, bias=True)\n","\n","        for param in net.parameters():\n","                param.requires_grad = False\n","        for param in net.classifier.parameters():\n","                param.requires_grad = True\n","\n","        return net\n","\n","def create_network_mobilenet():\n","        net = models.mobilenet_v3_small(pretrained=True)\n","        net.classifier[3] = nn.Linear(in_features=1024, out_features=8, bias=True)\n","\n","        for param in net.parameters():\n","            param.requires_grad = False\n","        for param in net.classifier.parameters():\n","            param.requires_grad = True\n","\n","        return net\n","\n","\n","def create_network_resnet():\n","        net = models.resnet18(pretrained=True)\n","        net.fc = nn.Linear(in_features=512, out_features=8, bias=True)\n","\n","        for param in net.parameters():\n","            param.requires_grad = False\n","        for param in net.fc.parameters():\n","            param.requires_grad = True\n","\n","        return net\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xDTi6y0Uk7N9"},"outputs":[],"source":["def run(config):  \n","    BASE_PATH = '/content/drive/MyDrive/Dissertation/skin_lesion_data/skin_lesion_part_1_models/'\n","    now = str(datetime.now()).replace(\":\", \"-\").replace(\" \", \"_\")\n","    RESULTS_PATH = os.path.join(BASE_PATH, now)\n","    os.makedirs(RESULTS_PATH, exist_ok=False)\n","\n","    with open(os.path.join(RESULTS_PATH, \"config.json\"), \"w\") as f:\n","        json.dump(config, f, indent=4)\n","\n","    if config.get(\"use_wandb\"):\n","        # this integrates the third-party platform, Weights and Biases,\n","        # with this notebook.\n","        run = wandb.init(\n","            project=\"part_1_skin_lesion\",\n","            entity=\"sarahlouise\",\n","            config=config,\n","        )\n","\n","\n","    # ## Train, validation and test set\n","    #\n","    # The train, validation and test sets were loaded and transformed using the Pytorch functions and amended classes previously discussed.\n","\n","    batch_size = config[\"batch_size\"]\n","    Imagenet_NV = ((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","\n","    print(\"Configuring datasets\")\n","    trainset = ImageFolder(\n","        os.path.join(config.get(\"data_path\"), 'train'),\n","        transform=transforms.Compose([\n","                            transforms.RandomVerticalFlip(0.5),\n","                            transforms.RandomHorizontalFlip(0.5),\n","                            transforms.RandomApply(nn.ModuleList([transforms.ColorJitter(),\n","                                                            transforms.GaussianBlur(3)]), p=0.1),\n","                            ImageResize(224,224),\n","                            transforms.PILToTensor(),\n","                            transforms.ConvertImageDtype(torch.float),\n","                            transforms.Normalize(*Imagenet_NV),\n","\n","                        ]))\n","\n","\n","    trainloader = torch.utils.data.DataLoader(\n","        trainset,\n","        batch_size=batch_size,\n","        num_workers=2,\n","        shuffle = True,\n","        #sampler=ImbalancedDatasetSampler(trainset, callback_get_label=lambda x: x.targets),\n","    )\n","\n","    valset = ImageFolder(\n","        os.path.join(config.get(\"data_path\"), 'val'),\n","        transform=transforms.Compose([\n","                            ImageResize(224,224),\n","                            transforms.PILToTensor(),\n","                            transforms.ConvertImageDtype(torch.float),\n","                            transforms.Normalize(*Imagenet_NV),\n","                        ]))\n","\n","    valloader = torch.utils.data.DataLoader(\n","        valset,\n","        batch_size=batch_size,\n","        shuffle=False,\n","        num_workers=2\n","    )\n","\n","    testset = ImageFolder(\n","        os.path.join(config.get(\"data_path\"), 'test'),\n","        transform=transforms.Compose([\n","                                ImageResize(224,224),\n","                                transforms.PILToTensor(),\n","                                transforms.ConvertImageDtype(torch.float),\n","                                transforms.Normalize(*Imagenet_NV),\n","                            ]))\n","\n","    testloader = torch.utils.data.DataLoader(\n","        testset,\n","        batch_size=batch_size,\n","        shuffle=False,\n","        num_workers=2\n","    )\n","    \n","    classes = sorted(os.listdir(os.path.join(config.get(\"data_path\"), 'train')))\n","\n","    if config.get(\"use_wandb\"):\n","        wandb.sklearn.plot_class_proportions(\n","            trainset.targets,\n","            testset.targets,\n","            classes\n","        )\n","\n","\n","    #making logical arguments from the configuration dictionary definied earlier\n","    model_name = config[\"model\"]\n","\n","    if model_name == \"densenet\":\n","        net = create_network_densenet()\n","    elif model_name == \"efficientnet\":\n","        net = create_network_efficientnet()\n","    elif model_name == \"mobilenet\":\n","        net = create_network_mobilenet()\n","    elif model_name == \"resnet\":\n","        net = create_network_resnet()\n","    else:\n","        raise ValueError(\"Model name not supported '{}'\".format(model_name))\n","\n","    print(f\"Moving network to {device}\")\n","    net = net.to(device)\n","\n","    # ## Training configurations\n","    \n","    # defining the training configurations\n","    no_of_epochs = config[\"epochs\"]\n","    \n","    # calculating class weights\n","    labels = np.array(trainset.targets)\n","    class_weights = class_weight.compute_class_weight(\n","        class_weight='balanced',\n","        classes=np.unique(labels),\n","        y=labels\n","    )\n","    class_weights = torch.tensor(\n","        class_weights,\n","        dtype=torch.float\n","    )\n","\n","    criterion = nn.CrossEntropyLoss(weight=class_weights).to(device)\n","    # criterion = nn.CrossEntropyLoss().to(device)\n","    optimizer = optim.Adam(\n","        net.parameters(),\n","        lr=config[\"lr\"],\n","        amsgrad=config[\"use_amsgrad\"]\n","    )\n","\n","    if config[\"use_warm_restarts\"]:\n","        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n","            optimizer,\n","            T_0=10,\n","            T_mult=1,\n","        )\n","    else:\n","        scheduler = optim.lr_scheduler.CosineAnnealingLR(\n","            optimizer,\n","            round((len(trainset)/batch_size)*no_of_epochs)\n","        )\n","\n","\n","    # ##  Model training\n","    #\n","    # This section included the training for the model. The network was set to train, a mini-batch was passed through the model and then the loss was then backpropagated. Each trained model was also automatically saved.\n","\n","    if config.get(\"use_wandb\"):\n","        wandb.watch(net)\n","\n","\n","    if not config.get(\"use_pretrained\"):\n","        print(\"Starting training\")\n","        for epoch in range(no_of_epochs):  # loop over the dataset multiple times\n","            print(\"Epoch {} of {}\".format(epoch+1, no_of_epochs))\n","            epoch_running_loss = []\n","            epoch_val_metric = []\n","            for i, data in tqdm(enumerate(trainloader, 1), total=len(trainloader)):\n","                current_step = (len(trainloader) * epoch) + i\n","                # get the inputs; data is a list of [inputs, labels]\n","                net.train()\n","                inputs, labels = data\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward + backward\n","                outputs = net(inputs)\n","                # outputs = torch.max(outputs, 1)\n","                loss = criterion(outputs, labels)\n","                loss.backward()\n","                optimizer.step()\n","                scheduler.step()\n","\n","                # saving loss statistics\n","                loss_val = loss.item()\n","                if config.get(\"use_wandb\"):\n","                    wandb.log(\n","                        {\n","                            \"train/bce_logits_loss\": loss_val,\n","                            \"train/lr\": scheduler.get_last_lr()[0],\n","                            \"train/custom_step\": (len(trainloader) * epoch) + i,\n","                        }\n","                    )\n","\n","                # adding in valiation data testing\n","                if i % 40 == 0:\n","                    model_name = \"{name}-epoch-{epoch}-step-{step}.pth\".format(\n","                        name=config[\"name\"],\n","                        epoch=epoch,\n","                        step=i,\n","                    )\n","                    model_path = os.path.join(RESULTS_PATH, model_name)\n","                    torch.save(net.state_dict(), model_path)\n","\n","                    predicted = []\n","                    actual = []\n","\n","                    print(\"Running validation\")\n","                    net.eval()\n","                    with torch.no_grad():\n","                        for i, data in enumerate(tqdm(valloader, total=len(valloader))):\n","                            inputs, labels = data\n","                            inputs = inputs.to(device)\n","                            labels = labels.to(device)\n","\n","                            outputs = net(inputs)\n","                            loss = criterion(outputs, labels)\n","                            if config.get(\"use_wandb\"):\n","                                wandb.log({\n","                                    \"val/loss\": loss,\n","                                    \"val/custom_step\": current_step,\n","                                })\n","\n","                            # collect the correct predictions for each class\n","                            actual.extend(labels.detach().cpu().numpy())\n","                            predicted.extend(torch.argmax(outputs, 1).detach().cpu().numpy())\n","\n","                        mb_acc = accuracy_score(actual, predicted)\n","                        precision = precision_score(actual, predicted, average=\"macro\", zero_division = 1)\n","                        recall = recall_score(actual, predicted, average=\"macro\", zero_division = 1)\n","                        f1 = f1_score(actual, predicted, average=\"macro\", zero_division = 1)\n","                        metric_report = classification_report(\n","                            np.array(actual),\n","                            np.array(predicted),\n","                            output_dict=True,\n","                            zero_division=1,\n","                        )\n","                        metric_report = {\n","                            f\"val_classes/{k}\": v\n","                            for k, v in metric_report.items()\n","                        }\n","                        metric_report.update({\n","                            \"val_classes/custom_step\": current_step,\n","                        })\n","\n","                        if config.get(\"use_wandb\"):\n","                            wandb.log({\n","                                \"val/accuracy\": mb_acc,\n","                                \"val/precision\": precision,\n","                                \"val/recall\": recall,\n","                                \"val/f1\": f1,\n","                                \"val/custom_step\": current_step\n","                            })\n","                            wandb.log(metric_report)\n","\n","\n","\n","        print('Finished Training')\n","        # saving each trained model\n","        model_name = '{}-final.pth'.format(\n","            config[\"name\"]\n","        )\n","        model_path = os.path.join(RESULTS_PATH, model_name)\n","        torch.save(net.state_dict(), model_path)\n","\n","        print(\"Final model saved\")\n","\n","    # ##  Model testing\n","    #\n","    # The model was set to evaluate mode for testing. The predicted and actual results were saved, and used for generating a confusion matrix and metrics.\n","    #\n","    # A confusion matrix was generated, showing the number of true positives and negatives, and false positives and negatives. Additionally, the metrics were calculated, including the accuracy score, precision and recall. The corresponding graphs were created using Weights and Biases.\n","\n","\n","    if config.get(\"use_pretrained\"):\n","        net.load_state_dict(\n","            torch.load(\n","                config.get(\"use_pretrained\")\n","            )\n","        )\n","\n","    predicted = []\n","    actual = []\n","\n","    print(\"Testing model\")\n","    # again no gradients needed\n","    net.eval()\n","    with torch.no_grad():\n","        for i, data in enumerate(tqdm(testloader, total=len(testloader))):\n","            inputs, labels = data\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            outputs = net(inputs)\n","            actual.extend(labels.detach().cpu().numpy())\n","            predicted.extend(torch.argmax(outputs, 1).detach().cpu().numpy())\n","\n","    print(\"Calculating performance metrics\")\n","    model_accuracy = accuracy_score(actual, predicted)\n","    model_precision = precision = precision_score(actual, predicted,\n","                                                average=\"macro\", zero_division = 1)\n","    model_recall = recall_score(actual, predicted,\n","                                average=\"macro\", zero_division = 1)\n","    model_f1 = f1_score(actual, predicted, average=\"macro\", zero_division = 1)\n","    metric_report = classification_report(\n","        np.array(actual),\n","        np.array(predicted),\n","        output_dict=True,\n","        zero_division=1,\n","    )\n","    metric_report = {\n","        f\"test_classes/{k}\": v\n","        for k, v in metric_report.items()\n","    }\n","\n","    if config.get(\"use_wandb\"):\n","        wandb.log({\"test/accuracy\": model_accuracy})\n","        wandb.log({\"test/precision\": model_precision})\n","        wandb.log({\"test/recall\": model_recall})\n","        wandb.log({\"test/f1\": model_f1})\n","        wandb.sklearn.plot_confusion_matrix(actual, predicted, classes)\n","    else:\n","        print(\"test/accuracy\", model_accuracy)\n","        print(\"test/precision\", model_precision)\n","        print(\"test/recall\", model_recall)\n","        print(\"test/f1\", model_f1)\n","\n","    plot_save_path = os.path.join(RESULTS_PATH, '{}_confusion_matrix.png'.format(\n","        config[\"name\"]\n","    ))\n","    print(\"Plotting confusion matrix in {}\".format(plot_save_path))\n","\n","    print(\"Calculating\")\n","    conf_matrix = confusion_matrix(y_true=actual, y_pred=predicted)\n","    print(\"Done\")\n","    fig =plt.figure(figsize=(20, 20))\n","    ax = fig.add_subplot(1,1,1)\n","    ax.matshow(conf_matrix, cmap=plt.cm.Reds)\n","\n","\n","    plt.xlabel('Predictions')\n","    plt.ylabel('Actuals')\n","    plt.title('Confusion Matrix')\n","    plt.savefig(plot_save_path)\n","    # plt.show()\n","\n","    if config.get(\"use_wandb\"):\n","        run.finish()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a78bfaf4824946a994918bfdc5a11c71","a1fbb282e49948c584e34bf42b2af5a6","178e9e53695245f1ab51ee33682c9233","04c9f02fa5394e52978330c0aad242a0","64d75d5fe4e34d348d74ff5836579250","11bf74855b2e4394911601af650eab36","14eee27f24b84ab1ae85960ba6eca74e","1178c77976654a0eab58a402ce3c508e","64243220f7934bb0b74e1a7aae6b0108","b00d2dc131da473994ff5f396ae11cea","1fb95217262c4bcf8ab18e95cde0ab42","a5663b52f6ea4dfc88e8a532e9ed9163","ca43476bde924e6297f3bc9736a0a547","c6e2d86bae644747ab72282238b0454f","98e579e38adf414f9e36afa3013e12e4","087a56e317bc4720b92df43226e328ac","c9cedffc99204c4c9da12e940a783d09","0e8e29bc9bee4a6daf574d8bbffc0e94","0b428094cf5648f89168d6906239dfff"]},"id":"xjSeEY5BUdey","outputId":"e9fe83e5-8c2a-410a-8d43-b461645a2ca1","executionInfo":{"status":"ok","timestamp":1652734951137,"user_tz":-60,"elapsed":9881755,"user":{"displayName":"Sarah-Louise Hayes","userId":"13751648430878105914"}}},"outputs":[{"data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["Tracking run with wandb version 0.12.16"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20220516_175542-1zu5hhzl</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/sarahlouise/part_1_skin_lesion/runs/1zu5hhzl\" target=\"_blank\">peachy-firebrand-47</a></strong> to <a href=\"https://wandb.ai/sarahlouise/part_1_skin_lesion\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Configuring datasets\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/densenet161-8d451a50.pth\" to /root/.cache/torch/hub/checkpoints/densenet161-8d451a50.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a78bfaf4824946a994918bfdc5a11c71","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0.00/110M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Moving network to cuda:0\n","Starting training\n","Epoch 1 of 5\n"]},{"output_type":"stream","name":"stderr","text":[" 49%|████▉     | 39/80 [59:47<1:09:46, 102.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [03:05<27:52, 185.88s/it]\u001b[A\n"," 20%|██        | 2/10 [03:06<10:14, 76.86s/it] \u001b[A\n"," 30%|███       | 3/10 [06:06<14:28, 124.05s/it]\u001b[A\n"," 40%|████      | 4/10 [06:09<07:37, 76.20s/it] \u001b[A\n"," 50%|█████     | 5/10 [09:04<09:19, 111.82s/it]\u001b[A\n"," 60%|██████    | 6/10 [09:08<05:00, 75.25s/it] \u001b[A\n"," 70%|███████   | 7/10 [12:02<05:22, 107.41s/it]\u001b[A\n"," 80%|████████  | 8/10 [12:05<02:28, 74.32s/it] \u001b[A\n"," 90%|█████████ | 9/10 [15:00<01:45, 105.63s/it]\u001b[A\n","100%|██████████| 10/10 [15:00<00:00, 90.09s/it]\n"," 99%|█████████▉| 79/80 [2:08:07<01:45, 105.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:12<01:48, 12.00s/it]\u001b[A\n"," 20%|██        | 2/10 [00:12<00:42,  5.29s/it]\u001b[A\n"," 30%|███       | 3/10 [00:22<00:50,  7.23s/it]\u001b[A\n"," 40%|████      | 4/10 [00:22<00:27,  4.60s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:32<00:32,  6.46s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:33<00:17,  4.48s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:38<00:14,  4.81s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:39<00:06,  3.47s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:49<00:05,  5.70s/it]\u001b[A\n","100%|██████████| 10/10 [00:50<00:00,  5.04s/it]\n","100%|██████████| 80/80 [2:08:59<00:00, 96.74s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 of 5\n"]},{"output_type":"stream","name":"stderr","text":[" 49%|████▉     | 39/80 [04:20<05:13,  7.65s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:22<03:21, 22.35s/it]\u001b[A\n"," 20%|██        | 2/10 [00:23<01:16,  9.62s/it]\u001b[A\n"," 30%|███       | 3/10 [00:39<01:28, 12.64s/it]\u001b[A\n"," 40%|████      | 4/10 [00:39<00:47,  7.90s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:50<00:44,  8.84s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:51<00:24,  6.04s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:56<00:17,  5.90s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:57<00:08,  4.23s/it]\u001b[A\n"," 90%|█████████ | 9/10 [01:07<00:06,  6.24s/it]\u001b[A\n","100%|██████████| 10/10 [01:08<00:00,  6.85s/it]\n"," 99%|█████████▉| 79/80 [09:23<00:06,  6.37s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:12<01:48, 12.05s/it]\u001b[A\n"," 20%|██        | 2/10 [00:12<00:42,  5.31s/it]\u001b[A\n"," 30%|███       | 3/10 [00:22<00:51,  7.33s/it]\u001b[A\n"," 40%|████      | 4/10 [00:22<00:28,  4.67s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:32<00:32,  6.51s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:33<00:17,  4.49s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:39<00:14,  4.90s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:39<00:07,  3.53s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:50<00:05,  5.76s/it]\u001b[A\n","100%|██████████| 10/10 [00:50<00:00,  5.09s/it]\n","100%|██████████| 80/80 [10:15<00:00,  7.69s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 of 5\n"]},{"output_type":"stream","name":"stderr","text":[" 49%|████▉     | 39/80 [04:18<04:49,  7.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:22<03:21, 22.34s/it]\u001b[A\n"," 20%|██        | 2/10 [00:23<01:16,  9.62s/it]\u001b[A\n"," 30%|███       | 3/10 [00:41<01:34, 13.55s/it]\u001b[A\n"," 40%|████      | 4/10 [00:42<00:50,  8.49s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:54<00:49,  9.93s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:55<00:27,  6.77s/it]\u001b[A\n"," 70%|███████   | 7/10 [01:00<00:19,  6.43s/it]\u001b[A\n"," 80%|████████  | 8/10 [01:01<00:09,  4.58s/it]\u001b[A\n"," 90%|█████████ | 9/10 [01:11<00:06,  6.42s/it]\u001b[A\n","100%|██████████| 10/10 [01:12<00:00,  7.26s/it]\n"," 99%|█████████▉| 79/80 [09:24<00:06,  6.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:12<01:48, 12.03s/it]\u001b[A\n"," 20%|██        | 2/10 [00:12<00:42,  5.34s/it]\u001b[A\n"," 30%|███       | 3/10 [00:22<00:50,  7.24s/it]\u001b[A\n"," 40%|████      | 4/10 [00:22<00:27,  4.63s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:32<00:32,  6.46s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:33<00:17,  4.47s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:38<00:14,  4.86s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:39<00:07,  3.51s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:49<00:05,  5.68s/it]\u001b[A\n","100%|██████████| 10/10 [00:50<00:00,  5.05s/it]\n","100%|██████████| 80/80 [10:16<00:00,  7.70s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4 of 5\n"]},{"output_type":"stream","name":"stderr","text":[" 49%|████▉     | 39/80 [04:24<05:10,  7.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:22<03:18, 22.07s/it]\u001b[A\n"," 20%|██        | 2/10 [00:22<01:15,  9.49s/it]\u001b[A\n"," 30%|███       | 3/10 [00:40<01:34, 13.48s/it]\u001b[A\n"," 40%|████      | 4/10 [00:41<00:50,  8.45s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:54<00:50, 10.12s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:55<00:27,  6.89s/it]\u001b[A\n"," 70%|███████   | 7/10 [01:01<00:19,  6.51s/it]\u001b[A\n"," 80%|████████  | 8/10 [01:01<00:09,  4.63s/it]\u001b[A\n"," 90%|█████████ | 9/10 [01:12<00:06,  6.47s/it]\u001b[A\n","100%|██████████| 10/10 [01:12<00:00,  7.29s/it]\n"," 99%|█████████▉| 79/80 [09:33<00:06,  6.35s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:11<01:47, 11.97s/it]\u001b[A\n"," 20%|██        | 2/10 [00:12<00:42,  5.29s/it]\u001b[A\n"," 30%|███       | 3/10 [00:22<00:50,  7.23s/it]\u001b[A\n"," 40%|████      | 4/10 [00:22<00:27,  4.62s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:32<00:32,  6.45s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:33<00:17,  4.46s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:38<00:14,  4.85s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:39<00:07,  3.51s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:49<00:05,  5.70s/it]\u001b[A\n","100%|██████████| 10/10 [00:50<00:00,  5.04s/it]\n","100%|██████████| 80/80 [10:24<00:00,  7.81s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5 of 5\n"]},{"output_type":"stream","name":"stderr","text":[" 49%|████▉     | 39/80 [04:26<05:13,  7.66s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:22<03:22, 22.47s/it]\u001b[A\n"," 20%|██        | 2/10 [00:23<01:17,  9.67s/it]\u001b[A\n"," 30%|███       | 3/10 [00:41<01:35, 13.62s/it]\u001b[A\n"," 40%|████      | 4/10 [00:42<00:51,  8.52s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:54<00:49,  9.92s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:55<00:27,  6.75s/it]\u001b[A\n"," 70%|███████   | 7/10 [01:00<00:19,  6.34s/it]\u001b[A\n"," 80%|████████  | 8/10 [01:01<00:09,  4.52s/it]\u001b[A\n"," 90%|█████████ | 9/10 [01:11<00:06,  6.38s/it]\u001b[A\n","100%|██████████| 10/10 [01:12<00:00,  7.24s/it]\n"," 99%|█████████▉| 79/80 [09:30<00:06,  6.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:12<01:48, 12.00s/it]\u001b[A\n"," 20%|██        | 2/10 [00:12<00:42,  5.30s/it]\u001b[A\n"," 30%|███       | 3/10 [00:22<00:50,  7.25s/it]\u001b[A\n"," 40%|████      | 4/10 [00:22<00:27,  4.64s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:32<00:32,  6.44s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:33<00:17,  4.45s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:38<00:14,  4.85s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:39<00:06,  3.50s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:50<00:05,  5.76s/it]\u001b[A\n","100%|██████████| 10/10 [00:50<00:00,  5.06s/it]\n","100%|██████████| 80/80 [10:21<00:00,  7.77s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Finished Training\n","Final model saved\n","Testing model\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [15:02<00:00, 90.22s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Calculating performance metrics\n","Plotting confusion matrix in /content/drive/MyDrive/Dissertation/skin_lesion_data/skin_lesion_part_1_models/2022-05-16_17-55-34.912401/densenet_confusion_matrix.png\n","Calculating\n","Done\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5663b52f6ea4dfc88e8a532e9ed9163"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>train/bce_logits_loss</td><td>█▆▄▂▂▂▂▂▂▁▂▂▁▂▂▂▂▂▂▁▂▁▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/custom_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/lr</td><td>███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val/accuracy</td><td>▁▇█▄█▆▇█▇█</td></tr><tr><td>val/custom_step</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>val/f1</td><td>▁▆█▃▇▇████</td></tr><tr><td>val/loss</td><td>▅▅▃▄▅▆▁▁▆▆▁▂█▄▂▆▃▅▁▄▄▄▂▆▅▄▁▅▄▄▁▅▄▄▂▅▄▄▂▄</td></tr><tr><td>val/precision</td><td>▁▆▆██▄▇▆▅▅</td></tr><tr><td>val/recall</td><td>▁▅▅▂▆▇████</td></tr><tr><td>val_classes/accuracy</td><td>▁▇█▄█▆▇█▇█</td></tr><tr><td>val_classes/custom_step</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test/accuracy</td><td>0.59313</td></tr><tr><td>test/f1</td><td>0.44532</td></tr><tr><td>test/precision</td><td>0.41217</td></tr><tr><td>test/recall</td><td>0.60513</td></tr><tr><td>train/bce_logits_loss</td><td>0.86265</td></tr><tr><td>train/custom_step</td><td>400</td></tr><tr><td>train/lr</td><td>0.0</td></tr><tr><td>val/accuracy</td><td>0.61113</td></tr><tr><td>val/custom_step</td><td>400</td></tr><tr><td>val/f1</td><td>0.43501</td></tr><tr><td>val/loss</td><td>1.17585</td></tr><tr><td>val/precision</td><td>0.41408</td></tr><tr><td>val/recall</td><td>0.55578</td></tr><tr><td>val_classes/accuracy</td><td>0.61113</td></tr><tr><td>val_classes/custom_step</td><td>400</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">peachy-firebrand-47</strong>: <a href=\"https://wandb.ai/sarahlouise/part_1_skin_lesion/runs/1zu5hhzl\" target=\"_blank\">https://wandb.ai/sarahlouise/part_1_skin_lesion/runs/1zu5hhzl</a><br/>Synced 5 W&B file(s), 2 media file(s), 2 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20220516_175542-1zu5hhzl/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 1440x1440 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["#from part_2 import run\n","\n","all_configs = [\n","            {\n","        \"epochs\": 5,\n","        \"batch_size\": 256,\n","        \"lr\": 1e-2,\n","        \"name\": \"densenet\",\n","        \"model\": \"densenet\",\n","        \"use_wandb\": True,\n","        \"use_amsgrad\": True,\n","        \"use_warm_restarts\": False,\n","        \"data_path\": \"/content/drive/MyDrive/Dissertation/skin_lesion_data/ISIC_2019_Split_val\",\n","        #\"use_pretrained\": \"./densenet-final.pth\",\n","    },\n","]\n","\n","for config in all_configs:\n","    run(config)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"quality_models.ipynb","provenance":[],"mount_file_id":"1MGy-NJAA8g75KYbGheTqnoQzj9Rl4iB4","authorship_tag":"ABX9TyPwadmyau+DP1h/TR+HY+ew"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a78bfaf4824946a994918bfdc5a11c71":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a1fbb282e49948c584e34bf42b2af5a6","IPY_MODEL_178e9e53695245f1ab51ee33682c9233","IPY_MODEL_04c9f02fa5394e52978330c0aad242a0"],"layout":"IPY_MODEL_64d75d5fe4e34d348d74ff5836579250"}},"a1fbb282e49948c584e34bf42b2af5a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_11bf74855b2e4394911601af650eab36","placeholder":"​","style":"IPY_MODEL_14eee27f24b84ab1ae85960ba6eca74e","value":"100%"}},"178e9e53695245f1ab51ee33682c9233":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1178c77976654a0eab58a402ce3c508e","max":115730790,"min":0,"orientation":"horizontal","style":"IPY_MODEL_64243220f7934bb0b74e1a7aae6b0108","value":115730790}},"04c9f02fa5394e52978330c0aad242a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b00d2dc131da473994ff5f396ae11cea","placeholder":"​","style":"IPY_MODEL_1fb95217262c4bcf8ab18e95cde0ab42","value":" 110M/110M [00:01&lt;00:00, 67.3MB/s]"}},"64d75d5fe4e34d348d74ff5836579250":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11bf74855b2e4394911601af650eab36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14eee27f24b84ab1ae85960ba6eca74e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1178c77976654a0eab58a402ce3c508e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64243220f7934bb0b74e1a7aae6b0108":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b00d2dc131da473994ff5f396ae11cea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fb95217262c4bcf8ab18e95cde0ab42":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5663b52f6ea4dfc88e8a532e9ed9163":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_ca43476bde924e6297f3bc9736a0a547","IPY_MODEL_c6e2d86bae644747ab72282238b0454f"],"layout":"IPY_MODEL_98e579e38adf414f9e36afa3013e12e4"}},"ca43476bde924e6297f3bc9736a0a547":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_087a56e317bc4720b92df43226e328ac","placeholder":"​","style":"IPY_MODEL_c9cedffc99204c4c9da12e940a783d09","value":"0.018 MB of 0.018 MB uploaded (0.000 MB deduped)\r"}},"c6e2d86bae644747ab72282238b0454f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e8e29bc9bee4a6daf574d8bbffc0e94","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0b428094cf5648f89168d6906239dfff","value":1}},"98e579e38adf414f9e36afa3013e12e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"087a56e317bc4720b92df43226e328ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9cedffc99204c4c9da12e940a783d09":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e8e29bc9bee4a6daf574d8bbffc0e94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b428094cf5648f89168d6906239dfff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}