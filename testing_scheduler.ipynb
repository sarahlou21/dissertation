{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"testing_scheduler.ipynb","provenance":[],"mount_file_id":"1izIGUQhsvnS2T847Pef9MMHSLQ0Bwts6","authorship_tag":"ABX9TyPsMLEXEPCcAWtZfe4bXLMC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"bf9915a4463749fd9d78cc3d3002e0c0":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_271781b0f04d4675bb3dbd3479a40045","IPY_MODEL_d0788496e2e2400e87bb19412473596c"],"layout":"IPY_MODEL_dc3dbf8c01bb449d9ed4b59b0f042c22"}},"271781b0f04d4675bb3dbd3479a40045":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0c5fb873dd74838a7204414abb85a39","placeholder":"​","style":"IPY_MODEL_65c0d8c645034e0180588f983ff67ea4","value":"0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\r"}},"d0788496e2e2400e87bb19412473596c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf9a1ae880cc457cbe2fddca8b398253","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8d6527c1ec1c426d9a266abb3b24394c","value":1}},"dc3dbf8c01bb449d9ed4b59b0f042c22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0c5fb873dd74838a7204414abb85a39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65c0d8c645034e0180588f983ff67ea4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf9a1ae880cc457cbe2fddca8b398253":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d6527c1ec1c426d9a266abb3b24394c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install -r /content/drive/MyDrive/Dissertation/requirements.txt -qqq\n","\n","from datetime import datetime\n","import json\n","import torch\n","import torchvision\n","import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","import os\n","import numpy as np\n","import torchvision.models as models\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch import argmax\n","from tqdm import tqdm\n","from PIL import Image\n","from matplotlib import pyplot as plt\n","import seaborn as sn\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score\n",")\n","from torchsampler import ImbalancedDatasetSampler\n","import wandb\n","import numpy as np\n","from os import listdir\n","from os.path import join, isdir\n","from glob import glob\n","import cv2\n","import timeit\n","import timm\n","from sklearn.metrics import confusion_matrix\n","from torchvision.datasets import ImageFolder\n","\n","#changing the device to GPU rather than CPU if it is available,\n","# this will decrease model training time.\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device {}\".format(device))\n","\n","torch.manual_seed(17)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SAf1KKjuwUWU","executionInfo":{"status":"ok","timestamp":1652351794117,"user_tz":-60,"elapsed":15238,"user":{"displayName":"Sarah-Louise Hayes","userId":"13751648430878105914"}},"outputId":"f7446b8c-50fc-43f1-c4b1-5c2b5523201d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device cuda:0\n"]},{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f31ef80bdb0>"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["class ImageResize(object):\n","        \"\"\"\n","        PIL's resize performs better than pytorch\n","        https://blog.zuru.tech/machine-learning/2021/08/09/the-dangers-behind-image-resizing\n","        \"\"\"\n","\n","        def __init__(self, new_h, new_w):\n","            self.new_h = new_h\n","            self.new_w = new_w\n","\n","        def __call__(self, image):\n","            image = image.resize((self.new_w, self.new_h), resample=Image.BILINEAR)\n","            return image"],"metadata":{"id":"zkA7avQBwn5K","executionInfo":{"status":"ok","timestamp":1652351794119,"user_tz":-60,"elapsed":13,"user":{"displayName":"Sarah-Louise Hayes","userId":"13751648430878105914"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def create_network_densenet():\n","        net = models.densenet161(pretrained=True)\n","        net.classifier = nn.Linear(in_features=2208, out_features=8, bias=True)\n","\n","        for param in net.parameters():\n","                param.requires_grad = False\n","        for param in net.classifier.parameters():\n","                param.requires_grad = True\n","\n","        return net\n","\n","\n","def create_network_efficientnet():\n","        net = models.efficientnet_b0(pretrained=True)\n","        net.classifier[1] = nn.Linear(in_features=1280, out_features=8, bias=True)\n","\n","        for param in net.parameters():\n","                param.requires_grad = False\n","        for param in net.classifier.parameters():\n","                param.requires_grad = True\n","\n","        return net\n","\n","def create_network_mobilenet():\n","        net = models.mobilenet_v3_small(pretrained=True)\n","        net.classifier[3] = nn.Linear(in_features=1024, out_features=8, bias=True)\n","\n","        for param in net.parameters():\n","            param.requires_grad = False\n","        for param in net.classifier.parameters():\n","            param.requires_grad = True\n","\n","        return net\n","\n","\n","def create_network_resnet():\n","        net = models.resnet18(pretrained=True)\n","        net.fc = nn.Linear(in_features=512, out_features=8, bias=True)\n","\n","        for param in net.parameters():\n","            param.requires_grad = False\n","        for param in net.fc.parameters():\n","            param.requires_grad = True\n","\n","        return net"],"metadata":{"id":"gyurnwfVyOEB","executionInfo":{"status":"ok","timestamp":1652351794479,"user_tz":-60,"elapsed":371,"user":{"displayName":"Sarah-Louise Hayes","userId":"13751648430878105914"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"LRw5xBNkozTq","executionInfo":{"status":"ok","timestamp":1652351795137,"user_tz":-60,"elapsed":662,"user":{"displayName":"Sarah-Louise Hayes","userId":"13751648430878105914"}}},"outputs":[],"source":["def run(config):\n","   \n","    BASE_PATH = '/content/drive/MyDrive/Dissertation/skin_lesion_data/skin_lesion_part_1_models/'\n","    now = str(datetime.now()).replace(\":\", \"-\").replace(\" \", \"_\")\n","    RESULTS_PATH = os.path.join(BASE_PATH, now)\n","    os.makedirs(RESULTS_PATH, exist_ok=False)\n","\n","    with open(os.path.join(RESULTS_PATH, \"config.json\"), \"w\") as f:\n","        json.dump(config, f, indent=4)\n","\n","    if config.get(\"use_wandb\"):\n","        # this integrates the third-party platform, Weights and Biases,\n","        # with this notebook.\n","        run = wandb.init(\n","            project=\"part_1_skin_lesion\",\n","            entity=\"sarahlouise\",\n","            config=config,\n","        )\n","\n","\n","    # Several custom classes were made. The first, ImageResize(), resizes an image using the PIL image resizer set to the bilinear function. A custom class was generated even though Pytorch has its own resizer, as discussed in the following article, https://blog.zuru.tech/machine-learning/2021/08/09/the-dangers-behind-image-resizing there are resizing issues associated with certain libraries such as Pytorch which introduce artefacts or don't provide sufficient antialiasing in the resized images using libraries such as Pytorch.\n","\n","    \n","\n","\n","    # ## Train, validation and test set\n","    #\n","    # The train, validation and test sets were loaded and transformed using the Pytorch functions and amended classes previously discussed.\n","\n","    batch_size = config[\"batch_size\"]\n","    Imagenet_NV = ((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","\n","    print(\"Configuring datasets\")\n","    trainset = ImageFolder(\n","        os.path.join(config.get(\"data_path\"), 'train'),\n","        transform=transforms.Compose([\n","                            transforms.RandomVerticalFlip(0.5),\n","                            transforms.RandomHorizontalFlip(0.5),\n","                            transforms.RandomApply(nn.ModuleList([transforms.ColorJitter(),\n","                                                            transforms.GaussianBlur(3)]), p=0.1),\n","                            ImageResize(224,224),\n","                            transforms.PILToTensor(),\n","                            transforms.ConvertImageDtype(torch.float),\n","                            transforms.Normalize(*Imagenet_NV),\n","\n","                        ]))\n","\n","\n","    trainloader = torch.utils.data.DataLoader(\n","        trainset,\n","        batch_size=batch_size,\n","        num_workers=2,\n","        sampler=ImbalancedDatasetSampler(trainset, callback_get_label=lambda x: x.targets),\n","    )\n","\n","    valset = ImageFolder(\n","        os.path.join(config.get(\"data_path\"), 'val'),\n","        transform=transforms.Compose([\n","                            ImageResize(224,224),\n","                            transforms.PILToTensor(),\n","                            transforms.ConvertImageDtype(torch.float),\n","                            transforms.Normalize(*Imagenet_NV),\n","                        ]))\n","\n","    valloader = torch.utils.data.DataLoader(\n","        valset,\n","        batch_size=batch_size,\n","        shuffle=False,\n","        num_workers=2\n","    )\n","\n","    testset = ImageFolder(\n","        os.path.join(config.get(\"data_path\"), 'test'),\n","        transform=transforms.Compose([\n","                                ImageResize(224,224),\n","                                transforms.PILToTensor(),\n","                                transforms.ConvertImageDtype(torch.float),\n","                                transforms.Normalize(*Imagenet_NV),\n","                            ]))\n","\n","    testloader = torch.utils.data.DataLoader(\n","        testset,\n","        batch_size=batch_size,\n","        shuffle=False,\n","        num_workers=2\n","    )\n","\n","    classes = sorted(os.listdir(os.path.join(config.get(\"data_path\"), 'train')))\n","\n","   \n","\n","    #making logical arguments from the configuration dictionary definied earlier\n","    model_name = config[\"model\"]\n","\n","    if model_name == \"densenet\":\n","        net = create_network_densenet()\n","    elif model_name == \"efficientnet\":\n","        net = create_network_efficientnet()\n","    elif model_name == \"mobilenet\":\n","        net = create_network_mobilenet()\n","    elif model_name == \"resnet\":\n","        net = create_network_resnet()\n","    else:\n","        raise ValueError(\"Model name not supported '{}'\".format(model_name))\n","\n","    print(\"Moving network to GPU\")\n","    net = net.to(device)\n","\n","    # ## Training configurations\n","    \n","\n","    # defining the training configurations\n","    no_of_epochs = config[\"epochs\"]\n","    criterion = nn.CrossEntropyLoss().to(device)\n","    optimizer = optim.Adam(\n","        net.parameters(),\n","        lr=config[\"lr\"],\n","        amsgrad=config[\"use_amsgrad\"]\n","    )\n","    if config[\"use_warm_restarts\"]:\n","        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n","            optimizer,\n","            T_0=100,\n","        )\n","    else:\n","        scheduler = optim.lr_scheduler.CosineAnnealingLR(\n","            optimizer,\n","            round((len(trainset)/batch_size)*no_of_epochs)\n","        )\n","\n","\n","    # ##  Model training\n","    #\n","    # This section included the training for the model. The network was set to train, a mini-batch was passed through the model and then the loss was then backpropagated. Each trained model was also automatically saved.\n","\n","    if config.get(\"use_wandb\"):\n","        wandb.watch(net)\n","\n","\n","    if not config.get(\"use_pretrained\"):\n","        print(\"Starting training\")\n","        for epoch in range(no_of_epochs):  # loop over the dataset multiple times\n","            print(\"Epoch {} of {}\".format(epoch, no_of_epochs))\n","            epoch_running_loss = []\n","            epoch_val_metric = []\n","            for i, data in tqdm(enumerate(trainloader, 1), total=len(trainloader)):\n","                # get the inputs; data is a list of [inputs, labels]\n","                net.train()\n","                inputs, labels = data\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward + backward\n","                outputs = net(inputs)\n","                # outputs = torch.max(outputs, 1)\n","                loss = criterion(outputs, labels)\n","                loss.backward()\n","                optimizer.step()\n","                scheduler.step()\n","\n","                # saving loss statistics\n","                loss_val = loss.item()\n","                epoch_running_loss.append(loss_val)\n","                if config.get(\"use_wandb\"):\n","                    wandb.log(\n","                        {\n","                            \"train/bce_logits_loss\": loss_val,\n","                            \"train/lr\": scheduler.get_last_lr()[0]\n","                        }\n","                    )\n","\n","                # adding in valiation data testing\n","                if i % 65 == 0:\n","                    model_name = \"{name}-epoch-{epoch}-step-{step}.pth\".format(\n","                        name=config[\"name\"],\n","                        epoch=epoch,\n","                        step=i,\n","                    )\n","                    model_path = os.path.join(RESULTS_PATH, model_name)\n","                    torch.save(net.state_dict(), model_path)\n","\n","                    predicted = []\n","                    actual = []\n","\n","                    print(\"Running validation\")\n","                    net.eval()\n","                    with torch.no_grad():\n","                        for i, data in enumerate(tqdm(valloader, total=len(valloader))):\n","                            inputs, labels = data\n","                            inputs = inputs.to(device)\n","                            labels = labels.to(device)\n","\n","                            outputs = net(inputs)\n","                            loss = criterion(outputs, labels)\n","                            if config.get(\"use_wandb\"):\n","                                wandb.log({\"val/loss\": loss})\n","\n","                            # collect the correct predictions for each class\n","                            actual.extend(labels.detach().cpu().numpy())\n","                            predicted.extend(torch.argmax(outputs, 1).detach().cpu().numpy())\n","\n","                        mb_acc = accuracy_score(actual, predicted)\n","\n","                        precision = precision_score(actual, predicted, average=\"macro\")\n","\n","                        recall = recall_score(actual, predicted, average=\"macro\")\n","                        if config.get(\"use_wandb\"):\n","                            wandb.log({\"val/accuracy\": mb_acc})\n","                            wandb.log({\"val/precision\": precision})\n","                            wandb.log({\"val/recall\": recall})\n","\n","\n","        print('Finished Training')\n","        # saving each trained model\n","        model_name = '{}-final.pth'.format(\n","            config[\"name\"]\n","        )\n","        model_path = os.path.join(RESULTS_PATH, model_name)\n","        torch.save(net.state_dict(), model_path)\n","\n","        print(\"Final model saved\")\n","\n","    # ##  Model testing\n","    #\n","    # The model was set to evaluate mode for testing. The predicted and actual results were saved, and used for generating a confusion matrix and metrics.\n","    #\n","    # A confusion matrix was generated, showing the number of true positives and negatives, and false positives and negatives. Additionally, the metrics were calculated, including the accuracy score, precision and recall. The corresponding graphs were created using Weights and Biases.\n","\n","\n","    if config.get(\"use_pretrained\"):\n","        net.load_state_dict(\n","            torch.load(\n","                config.get(\"use_pretrained\")\n","            )\n","        )\n","\n","    predicted = []\n","    actual = []\n","\n","    print(\"Testing model\")\n","    # again no gradients needed\n","    net.eval()\n","    with torch.no_grad():\n","        for i, data in enumerate(tqdm(testloader, total=len(testloader))):\n","            inputs, labels = data\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            outputs = net(inputs)\n","            actual.extend(labels.detach().cpu().numpy())\n","            predicted.extend(torch.argmax(outputs, 1).detach().cpu().numpy())\n","\n","    print(\"Calculating performance metrics\")\n","    model_accuracy = accuracy_score(actual, predicted)\n","    model_precision = precision = precision_score(actual, predicted,\n","                                                average=\"macro\")\n","    model_recall = recall_score(actual, predicted,\n","                                average=\"macro\")\n","\n","    if config.get(\"use_wandb\"):\n","        wandb.log({\"test/accuracy\": model_accuracy})\n","        wandb.log({\"test/precision\": model_precision})\n","        wandb.log({\"test/recall\": model_recall})\n","    else:\n","        print(\"test/accuracy\", model_accuracy)\n","        print(\"test/precision\", model_precision)\n","        print(\"test/recall\", model_recall)\n","\n","    plot_save_path = os.path.join(RESULTS_PATH, '{}_confusion_matrix.png'.format(\n","        config[\"name\"]\n","    ))\n","    print(\"Plotting confusion matrix in {}\".format(plot_save_path))\n","\n","    print(\"Calculating\")\n","    conf_matrix = confusion_matrix(y_true=actual, y_pred=predicted)\n","    print(\"Done\")\n","    fig =plt.figure(figsize=(20, 20))\n","    ax = fig.add_subplot(1,1,1)\n","    ax.matshow(conf_matrix, cmap=plt.cm.Reds)\n","\n","\n","    plt.xlabel('Predictions')\n","    plt.ylabel('Actuals')\n","    plt.title('Confusion Matrix')\n","    plt.savefig(plot_save_path)\n","    # plt.show()\n","\n","    if config.get(\"use_wandb\"):\n","        run.finish()\n"]},{"cell_type":"code","source":["#from part_2 import run\n","\n","all_configs = [\n","            {\n","        \"epochs\": 5,\n","        \"batch_size\": 128,\n","        \"lr\": 1e-2,\n","        \"name\": \"densenet\",\n","        \"model\": \"densenet\",\n","        \"use_wandb\": True,\n","        \"use_amsgrad\": True,\n","        \"use_warm_restarts\": False,\n","        \"data_path\": \"/content/drive/MyDrive/Dissertation/skin_lesion_data/ISIC_2019_Split_val\",\n","        #\"use_pretrained\": \"./densenet-final.pth\",\n","    },\n","]\n","\n","for config in all_configs:\n","    run(config)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":842,"referenced_widgets":["bf9915a4463749fd9d78cc3d3002e0c0","271781b0f04d4675bb3dbd3479a40045","d0788496e2e2400e87bb19412473596c","dc3dbf8c01bb449d9ed4b59b0f042c22","b0c5fb873dd74838a7204414abb85a39","65c0d8c645034e0180588f983ff67ea4","bf9a1ae880cc457cbe2fddca8b398253","8d6527c1ec1c426d9a266abb3b24394c"]},"id":"jKpkyEJlxFLH","executionInfo":{"status":"error","timestamp":1652352880293,"user_tz":-60,"elapsed":686852,"user":{"displayName":"Sarah-Louise Hayes","userId":"13751648430878105914"}},"outputId":"07aac5f3-5af8-40d7-cf42-35bfe77fe760"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Finishing last run (ID:3348vshf) before initializing another..."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf9915a4463749fd9d78cc3d3002e0c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/bce_logits_loss</td><td>▁▇█▇▄▆▆▄▃▃▂▂▁▁▁▁▁▂</td></tr><tr><td>train/lr</td><td>████▇▇▇▇▆▆▅▅▄▄▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/bce_logits_loss</td><td>2.16257</td></tr><tr><td>train/lr</td><td>0.00995</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">upbeat-cherry-32</strong>: <a href=\"https://wandb.ai/sarahlouise/part_1_skin_lesion/runs/3348vshf\" target=\"_blank\">https://wandb.ai/sarahlouise/part_1_skin_lesion/runs/3348vshf</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20220512_103638-3348vshf/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Successfully finished last run (ID:3348vshf). Initializing new run:<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.12.16"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20220512_104313-2vpyz576</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/sarahlouise/part_1_skin_lesion/runs/2vpyz576\" target=\"_blank\">sunny-durian-33</a></strong> to <a href=\"https://wandb.ai/sarahlouise/part_1_skin_lesion\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Configuring datasets\n","Moving network to GPU\n","Starting training\n","Epoch 0 of 5\n"]},{"output_type":"stream","name":"stderr","text":[" 40%|████      | 64/159 [10:10<17:08, 10.83s/it]"]},{"output_type":"stream","name":"stdout","text":["Running validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:37<11:51, 37.43s/it]\u001b[A\n"," 10%|█         | 2/20 [01:03<09:33, 31.84s/it]\n"," 40%|████      | 64/159 [11:16<16:43, 10.57s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-eb7c0306be16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_configs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-4-d2ddc5bd1af9>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    189\u001b[0m                     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m                             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}